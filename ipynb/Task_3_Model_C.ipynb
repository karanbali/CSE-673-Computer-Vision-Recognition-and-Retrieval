{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Task_3_Model_C.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EA7VaH7Ydxy"
      },
      "source": [
        "# Task 3: Model_C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm3JXBTYMGnx"
      },
      "source": [
        "### Import Dependencies and download \"Tiny-ImageNet-200\" dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xlJXbSs8Xgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b64144-ec88-4686-f524-f80b4f9fbfc8"
      },
      "source": [
        "# Mounting Google drive for loading the checkpoint.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cd gdrive/MyDrive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeloaBMkxvhi",
        "outputId": "39af7cfd-b50d-4aa4-b3af-092b22bad445"
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip && ls tiny-imagenet-200\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import torchvision.models as models\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "cuda = torch.device('cuda') \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-05 21:12:39--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  10.7MB/s    in 19s     \n",
            "\n",
            "2021-11-05 21:12:58 (12.5 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n",
            "test  train  val  wnids.txt  words.txt\n",
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzDGwZoxMUHX"
      },
      "source": [
        "### Preprocessing: Collate all image's path address & labels as a input to custom pytorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HVW1-sJyWsJ"
      },
      "source": [
        "file_list = []\n",
        "\n",
        "\n",
        "for folder in os.listdir('./tiny-imagenet-200/train/'):\n",
        "\n",
        "\n",
        "  label = folder \n",
        "  for file in os.listdir('./tiny-imagenet-200/train/' + folder + '/images/'):\n",
        "    file_dir = './tiny-imagenet-200/train/' + folder + '/images/' + file\n",
        "\n",
        "    file_list.append((file_dir))\n",
        "\n",
        "with open('./tiny-imagenet-200/wnids.txt',) as f:\n",
        "\n",
        "  id_list = {}\n",
        "  read_data = f.readlines()\n",
        "  for i, val in enumerate(read_data):\n",
        "    id_list[val.replace('\\n', '')] = i\n",
        "\n",
        "\n",
        "test_list = []\n",
        "test_id = {}\n",
        "with open('./tiny-imagenet-200/val/val_annotations.txt', 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    file, label = line.split()[0:2]\n",
        "    file_dir = './tiny-imagenet-200/val/images/' + file\n",
        "\n",
        "    test_list.append((file_dir))\n",
        "    test_id[file] = label"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQwYYGpPNdu-"
      },
      "source": [
        "### Custom Pytorch datatset for training images of \"Tiny-ImageNet-200\" dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EytwpRzykLF"
      },
      "source": [
        "class TrainTinyImageNetDataset(Dataset):\n",
        "    def __init__(self, f_list, id, transform=None):\n",
        "\n",
        "        self.filenames = f_list\n",
        "        self.transform = transform\n",
        "        self.id_dict = id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = self.filenames[idx]\n",
        "        image = None\n",
        "       \n",
        "        with open(img_path, 'rb') as f:\n",
        "          image = Image.open(f)\n",
        "          image =  image.convert('RGB')\n",
        "          \n",
        "        \n",
        "       \n",
        "\n",
        "        label = self.id_dict[img_path.split('/')[-1].split('.')[0].split('_')[0]]\n",
        "       \n",
        "\n",
        "        if self.transform is not None:\n",
        "\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, label\n",
        "\n",
        "\n",
        "class TrainSet(TrainTinyImageNetDataset):\n",
        "  \n",
        "    def __init__(self, f_list, id, transform=None):\n",
        "\n",
        "        super(TrainSet, self).__init__(f_list, id, transform=transform)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2VBY3rZNpiS"
      },
      "source": [
        "### Custom Pytorch datatset for testing images of \"Tiny-ImageNet-200\" dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KOWAGrxy2-E"
      },
      "source": [
        "class TestTinyImageNetDataset(Dataset):\n",
        "    def __init__(self, t_list, id, cls_id, transform=None):\n",
        "        self.filenames = t_list\n",
        "        self.transform = transform\n",
        "        self.id_dict = id\n",
        "        self.cls_id = cls_id\n",
        "       \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.filenames[idx]\n",
        "        image = None\n",
        "       \n",
        "        with open(img_path, 'rb') as f:\n",
        "          image = Image.open(f)\n",
        "          image =  image.convert('RGB')\n",
        "    \n",
        "        label = self.cls_id[self.id_dict[img_path.split('/')[-1]]]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "       "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFlNKw85ON_7"
      },
      "source": [
        "### CUBS Block 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5arFr_LzNJd"
      },
      "source": [
        "class CUBS1(nn.Module):\n",
        "  def __init__(self, channels_in, n_in):\n",
        "      super(CUBS1, self).__init__()\n",
        "      self.channels_in = channels_in\n",
        "      self.n_in = n_in\n",
        "      self.dense_1_1 = nn.Linear(channels_in,n_in)\n",
        "      self.dense_1_2 = nn.Linear(channels_in,n_in)\n",
        "      self.dense_1_3 = nn.Linear(channels_in,n_in)\n",
        "      self.dense_2 = nn.Linear(n_in,channels_in)\n",
        "      self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    \n",
        "\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "      self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def CB1_Sim1(self, a, b):\n",
        "    a_norm = torch.nn.functional.normalize(a, dim=2)\n",
        "    b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "    sim_matrix = torch.matmul(a_norm[0].T, b_norm[0])\n",
        "    sim_matrix = sim_matrix.reshape((1,self.n_in,self.n_in))\n",
        "\n",
        "\n",
        "    for i in range(1,a.shape[0]):\n",
        "  \n",
        "      mul = torch.matmul(a_norm[i].T, b_norm[i]) \n",
        "      mul = mul.reshape((1,self.n_in,self.n_in))\n",
        "      sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "      \n",
        "\n",
        "    \n",
        "\n",
        "    return sim_matrix\n",
        "\n",
        "\n",
        "  def CB1_Sim2(self, a, b):\n",
        "    b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "    sim_matrix = torch.matmul(a[0], b_norm[0].T)\n",
        "    sim_matrix = sim_matrix.reshape((1,1,self.n_in))\n",
        "\n",
        "\n",
        "    for i in range(1,a.shape[0]):\n",
        "      mul = torch.matmul(a[i], b_norm[i].T)\n",
        "      mul = mul.reshape((1,1,self.n_in))\n",
        "      sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "\n",
        "    return sim_matrix\n",
        "\n",
        "  def CB1_Softmax(self, a):\n",
        "    out_matrix = nn.Softmax(dim=1)(a[0])\n",
        "    out_matrix = out_matrix.reshape((1,self.n_in,self.n_in))\n",
        "\n",
        "    for i in range(1,a.shape[0]):\n",
        "      sim = nn.Softmax(dim=1)(a[i])\n",
        "      sim = sim.reshape((1,self.n_in,self.n_in))\n",
        "      out_matrix = torch.vstack((out_matrix,sim))\n",
        "\n",
        "    return out_matrix\n",
        "\n",
        "  def CB1_Channel(self, a, b):\n",
        "    out_matrix = b[0] * a[0].unsqueeze(dim=-1). unsqueeze(dim=-1)\n",
        "\n",
        "    for i in range(1,a.shape[0]): \n",
        "      mul = b[i] * a[i].unsqueeze(dim=-1). unsqueeze(dim=-1)\n",
        "      out_matrix = torch.vstack((out_matrix,mul))\n",
        "\n",
        "    return out_matrix\n",
        "\n",
        "      \n",
        "  \n",
        "\n",
        "  def forward(self, x):\n",
        "      x_pool = self.avgpool(x)\n",
        "      x_pool = torch.reshape(x_pool,(x.shape[0],1,x.shape[1]))\n",
        "\n",
        "     \n",
        "\n",
        "      x_1_1 = self.dense_1_1(x_pool)\n",
        "     \n",
        "      \n",
        "      x_1_1 = self.relu(x_1_1)\n",
        "\n",
        "      x_1_2 = self.dense_1_2(x_pool)\n",
        "      x_1_2 = self.relu(x_1_2)\n",
        "\n",
        "      x_1_3 = self.dense_1_3(x_pool)\n",
        "      x_1_3 = self.relu(x_1_3)\n",
        "\n",
        "     \n",
        "      x_1_2_sim = self.CB1_Sim1(x_1_1, x_1_2)\n",
        "\n",
        "\n",
        "            \n",
        "      x_1_2_softmax = self.CB1_Softmax(x_1_2_sim)\n",
        "\n",
        "  \n",
        "      x_1_2_3_sim = self.CB1_Sim2(x_1_3, x_1_2_softmax)\n",
        "      \n",
        "      x_2 = self.dense_2(x_1_2_3_sim)\n",
        "      x_2 = self.relu(x_2)\n",
        "\n",
        "      x_concat_1 = torch.add(x_2, x_pool)\n",
        "      x_sig = self.sig(x_concat_1)\n",
        "\n",
        "\n",
        "      x_out = self.CB1_Channel(x_sig, x)\n",
        "      return x_out\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYc-zspuOS89"
      },
      "source": [
        "### CUBS Block 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EJGDFNEzXda"
      },
      "source": [
        "\n",
        "class CUBS2(nn.Module):\n",
        "  def __init__(self, channels_in, n_in):\n",
        "      super(CUBS2, self).__init__()\n",
        "      self.channels_in = channels_in\n",
        "      self.n_in = n_in\n",
        "\n",
        "\n",
        "      self.conv_1_1 = nn.Conv2d(channels_in, 1, kernel_size=1)\n",
        "      self.conv_1_2 = nn.Conv2d(channels_in, 1, kernel_size=1)\n",
        "      self.conv_1_3 = nn.Conv2d(channels_in, 1, kernel_size=1)\n",
        "      \n",
        "   \n",
        "      \n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "      self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def CB2_Sim1(self, a, b):\n",
        "\n",
        "      a = torch.flatten(a, start_dim=2, end_dim=3)    \n",
        "      b = torch.flatten(b, start_dim=2, end_dim=3)\n",
        "\n",
        "      a_norm = torch.nn.functional.normalize(a, dim=2)\n",
        "      b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "      sim_matrix = torch.matmul(a_norm[0].T, b_norm[0])\n",
        "      sim_matrix = sim_matrix.reshape((1,a.shape[2],a.shape[2]))\n",
        "\n",
        "\n",
        "      for i in range(1,a.shape[0]):\n",
        "    \n",
        "        mul = torch.matmul(a_norm[i].T, b_norm[i]) \n",
        "        mul = mul.reshape((1,a.shape[2],a.shape[2]))\n",
        "        sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "        \n",
        "\n",
        "      return sim_matrix\n",
        "\n",
        "\n",
        "  def CB2_Sim2(self, a, b):\n",
        "\n",
        "      a = torch.flatten(a, start_dim=2, end_dim=3)\n",
        "      b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "      sim_matrix = torch.matmul(a[0], b_norm[0].T)\n",
        "      sim_matrix = sim_matrix.reshape((1,1,a.shape[2]))\n",
        "\n",
        "\n",
        "      for i in range(1,a.shape[0]):\n",
        "        mul = torch.matmul(a[i], b_norm[i].T)\n",
        "        mul = mul.reshape((1,1,a.shape[2]))\n",
        "        sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "\n",
        "      return sim_matrix\n",
        "\n",
        "\n",
        "  def CB2_Softmax(self, a):\n",
        "      out_matrix = nn.Softmax(dim=1)(a[0])\n",
        "      out_matrix = out_matrix.reshape((1,a.shape[2],a.shape[2]))\n",
        "\n",
        "      for i in range(1,a.shape[0]):\n",
        "        sim = nn.Softmax(dim=1)(a[i])\n",
        "        sim = sim.reshape((1,a.shape[2],a.shape[2]))\n",
        "        out_matrix = torch.vstack((out_matrix,sim))\n",
        "\n",
        "      return out_matrix\n",
        "\n",
        "  \n",
        "\n",
        "  def bmul(self, vec, mat, axis=0):\n",
        "      mat = mat.transpose(axis, -1)\n",
        "      return (mat * vec.expand_as(mat)).transpose(axis, -1)\n",
        "\n",
        "  def CB1_Pixel(self, a, b):\n",
        "      a = torch.reshape(a, (a.shape[0],b.shape[2],b.shape[3]))\n",
        "    \n",
        "      a_0 = a[0]\n",
        "      b_0 = b[0]\n",
        "      out_matrix = self.bmul(a_0,b_0, axis=2)\n",
        "      out_matrix = out_matrix.reshape((1,b.shape[1],b.shape[2],b.shape[3]))\n",
        "\n",
        "      for i in range(1, a.shape[0]):\n",
        "        ai = a[i]\n",
        "        \n",
        "        bi = b[i]\n",
        "      \n",
        "        mul = self.bmul(ai,bi, axis=2)\n",
        "        mul = mul.reshape((1,b.shape[1],b.shape[2],b.shape[3]))\n",
        "        out_matrix = torch.vstack((out_matrix,mul))\n",
        "\n",
        "      return out_matrix\n",
        "      \n",
        "  def forward(self, x):\n",
        "\n",
        "     \n",
        "      x_1_1 = self.conv_1_1(x)\n",
        "      x_1_1 = self.relu(x_1_1)\n",
        "\n",
        "      x_1_2 = self.conv_1_2(x)\n",
        "      x_1_2 = self.relu(x_1_2)\n",
        "\n",
        "      x_1_3 = self.conv_1_3(x)\n",
        "      x_1_3 = self.relu(x_1_3)\n",
        "\n",
        "     \n",
        "      x_1_2_sim = self.CB2_Sim1(x_1_1, x_1_2)\n",
        "\n",
        "      x_1_2_softmax = self.CB2_Softmax(x_1_2_sim)\n",
        "\n",
        "     \n",
        "      x_1_2_3_sim = self.CB2_Sim2(x_1_3, x_1_2_softmax)\n",
        "      \n",
        "      x_sig = self.sig(x_1_2_3_sim)\n",
        "\n",
        "     \n",
        "      x_out = self.CB1_Pixel(x_sig, x)\n",
        "      \n",
        "      return x_out\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6QmOSHhOYqj"
      },
      "source": [
        "### This section contains Open-Sourced \"ResNet-18\" implementation along with various modifications and CUBS Blocks(1 & 2) experiments mentioned in the assignment.\n",
        "\n",
        "***\n",
        "\n",
        "### I've modified the \"BasicBlock\" of open-sourced ResNet-18 implementations to get new \"BasicBlock_A\", \"BasicBlock_B\" and \"BasicBlock_C\" defining the all 3 different configurations that were given as a task.\n",
        "\n",
        "***\n",
        "\n",
        "### BasicBlock_A : Parallel CUBS 1 & CUBS 2\n",
        "### BasicBlock_B : CUBS 1 -> CUBS 2\n",
        "### BasicBlock_C : CUBS 2 -> CUBS 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaKzw2yczttS"
      },
      "source": [
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
        "           'wide_resnet50_2', 'wide_resnet101_2']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class BasicBlock_A(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock_A, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.cubs1 = CUBS1(planes, 30)\n",
        "        self.cubs2 = CUBS2(planes, 30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # Parallel CUBS 1 & CUBS 2\n",
        "        out_cubs1 = self.cubs1(out)\n",
        "        out_cubs2 = self.cubs2(out)\n",
        "\n",
        "        out = out_cubs1 + out_cubs2\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class BasicBlock_B(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock_B, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.cubs1 = CUBS1(planes, 30)\n",
        "        self.cubs2 = CUBS2(planes, 30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # CUBS 1 -> CUBS 2\n",
        "        out = self.cubs1(out)\n",
        "        out = self.cubs2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class BasicBlock_C(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock_C, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.cubs1 = CUBS1(planes, 30)\n",
        "        self.cubs2 = CUBS2(planes, 30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # CUBS 2 -> CUBS 1\n",
        "        out = self.cubs2(out)\n",
        "        out = self.cubs1(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=200, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWAyWPSrV7xg"
      },
      "source": [
        "### Defining 4 different models for vanilla ResNet-18, Model_A, Model_B & Model_C with different variations of \"BasicBlock\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLRRshHh0fOG"
      },
      "source": [
        "def resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "    \n",
        "\n",
        "def model_A(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock_A, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "    \n",
        "\n",
        "def model_B(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock_B, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "    \n",
        "\n",
        "def model_C(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock_C, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t1FDzZyWSXF"
      },
      "source": [
        "### Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGaWrdlCzzh2"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      \n",
        "        X, y = X.to(device), y.long().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        torch.set_grad_enabled(True)\n",
        "        \n",
        "        pred = model(X).float()\n",
        "       \n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "       \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    \n",
        "        if batch % 1000 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv7QwhDXWXOV"
      },
      "source": [
        "### Testing Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pts-sMZ6z86K"
      },
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "          \n",
        "            X, y = X.to(device), y.long().to(device)\n",
        "            torch.set_grad_enabled(False)\n",
        "            pred = model(X).float()\n",
        "       \n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-YM-OZXWbvU"
      },
      "source": [
        "### Defining \"Learning Rate Scheduler\" & \"Early stopping mechanism\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irq8901N-Jo7"
      },
      "source": [
        "class LRScheduler():\n",
        "  \n",
        "    def __init__(\n",
        "        self, optimizer, patience=5, min_lr=1e-7, factor=0.75\n",
        "    ):\n",
        "        \n",
        "        self.optimizer = optimizer\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
        "                self.optimizer,\n",
        "                mode='min',\n",
        "                patience=self.patience,\n",
        "                factor=self.factor,\n",
        "                min_lr=self.min_lr,\n",
        "                verbose=True\n",
        "            )\n",
        "    def __call__(self, val_loss):\n",
        "        self.scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "class EarlyStopping():\n",
        "   \n",
        "    def __init__(self, patience=10, min_delta=0):\n",
        "      \n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss == None:\n",
        "            self.best_loss = val_loss\n",
        "        elif self.best_loss - val_loss > self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        elif self.best_loss - val_loss < self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93aTm1cM5fx2"
      },
      "source": [
        "### Instantiating Dataset loaders for training & testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4GR1wYJ-TUz"
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "trans = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "trainset = TrainSet(f_list=file_list,id=id_list, transform=trans)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=5, shuffle=True, num_workers=4)\n",
        "\n",
        "trans_test = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "testset = TestTinyImageNetDataset(t_list=test_list,id=test_id, cls_id =id_list,  transform=trans_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False, num_workers=4)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tG5NgW7XqFy"
      },
      "source": [
        "### Instantiating & training & checkpoint \"Model_C\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGFul9OWB2l3"
      },
      "source": [
        "#### There are 2 cells for \"Model_C\" that are given below.\n",
        "#### Run the 1st cell in case you want to load a checkpoint & resume training.\n",
        "#### Else Run the 2nd cell in case you want to start training from scratch.\n",
        "\n",
        "#### **NOTE: Make sure to change the path of loading the checkpoint in 1st cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f-HNzTz2lDN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7cf8eeb-f24e-4973-8a4e-e41c0ed5f307"
      },
      "source": [
        "model_C = model_C(pretrained=False, progress=True)\n",
        "model_C = model_C.to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer_model_C = torch.optim.Adam(model_C.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "# **NOTE: Make sure to change the path of loading the checkpoint in 1st cell**\n",
        "checkpoint = torch.load('gdrive/MyDrive/Fall_21/trained-model_C-model.ckpt')\n",
        "\n",
        "\n",
        "model_C.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer_model_C.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch'] + 1\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "es =  EarlyStopping()\n",
        "lrs = LRScheduler(optimizer_model_C)\n",
        "\n",
        "checkpoint_dir = \".\"\n",
        "test_loss = 0\n",
        "epochs = 20\n",
        "for i in range(epochs):\n",
        "    print(f\"Epoch {i+1}\")\n",
        "    train(trainloader, model_C, loss_fn, optimizer_model_C)\n",
        "    test_loss = test(testloader, model_C, loss_fn)\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': i+1,\n",
        "        'model_state_dict': model_C.state_dict(),\n",
        "        'optimizer_state_dict': optimizer_model_C.state_dict(),\n",
        "        'loss': test_loss\n",
        "        }, checkpoint_dir+'/%04d-model_C-model.ckpt' %i)\n",
        "    \n",
        "    lrs(test_loss)\n",
        "    es(test_loss)\n",
        "    if es.early_stop: \n",
        "         break\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 5.727295  [    0/100000]\n",
            "loss: 3.400599  [ 5000/100000]\n",
            "loss: 2.920736  [10000/100000]\n",
            "loss: 4.046310  [15000/100000]\n",
            "loss: 3.186893  [20000/100000]\n",
            "loss: 4.349616  [25000/100000]\n",
            "loss: 2.452876  [30000/100000]\n",
            "loss: 2.749555  [35000/100000]\n",
            "loss: 5.268440  [40000/100000]\n",
            "loss: 2.430785  [45000/100000]\n",
            "loss: 4.107427  [50000/100000]\n",
            "loss: 4.291731  [55000/100000]\n",
            "loss: 4.403447  [60000/100000]\n",
            "loss: 3.395289  [65000/100000]\n",
            "loss: 4.263890  [70000/100000]\n",
            "loss: 3.282525  [75000/100000]\n",
            "loss: 2.508016  [80000/100000]\n",
            "loss: 3.000059  [85000/100000]\n",
            "loss: 4.309838  [90000/100000]\n",
            "loss: 3.151799  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 36.8%, Avg loss: 2.723032 \n",
            "\n",
            "Epoch 2\n",
            "loss: 4.166368  [    0/100000]\n",
            "loss: 2.074565  [ 5000/100000]\n",
            "loss: 2.579685  [10000/100000]\n",
            "loss: 2.678803  [15000/100000]\n",
            "loss: 3.799941  [20000/100000]\n",
            "loss: 3.775825  [25000/100000]\n",
            "loss: 3.863680  [30000/100000]\n",
            "loss: 2.032346  [35000/100000]\n",
            "loss: 2.307470  [40000/100000]\n",
            "loss: 1.731482  [45000/100000]\n",
            "loss: 2.744329  [50000/100000]\n",
            "loss: 3.476429  [55000/100000]\n",
            "loss: 2.283050  [60000/100000]\n",
            "loss: 1.697670  [65000/100000]\n",
            "loss: 2.744623  [70000/100000]\n",
            "loss: 0.699465  [75000/100000]\n",
            "loss: 1.594210  [80000/100000]\n",
            "loss: 2.067241  [85000/100000]\n",
            "loss: 4.042720  [90000/100000]\n",
            "loss: 2.064319  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 41.2%, Avg loss: 2.487049 \n",
            "\n",
            "Epoch 3\n",
            "loss: 2.700675  [    0/100000]\n",
            "loss: 1.732006  [ 5000/100000]\n",
            "loss: 2.378026  [10000/100000]\n",
            "loss: 2.099398  [15000/100000]\n",
            "loss: 4.963742  [20000/100000]\n",
            "loss: 2.252467  [25000/100000]\n",
            "loss: 1.942049  [30000/100000]\n",
            "loss: 2.031669  [35000/100000]\n",
            "loss: 3.131379  [40000/100000]\n",
            "loss: 1.960811  [45000/100000]\n",
            "loss: 0.700258  [50000/100000]\n",
            "loss: 2.741583  [55000/100000]\n",
            "loss: 2.606483  [60000/100000]\n",
            "loss: 1.460481  [65000/100000]\n",
            "loss: 2.151349  [70000/100000]\n",
            "loss: 1.606596  [75000/100000]\n",
            "loss: 3.026353  [80000/100000]\n",
            "loss: 2.577522  [85000/100000]\n",
            "loss: 2.826228  [90000/100000]\n",
            "loss: 3.311697  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 44.6%, Avg loss: 2.329799 \n",
            "\n",
            "Epoch 4\n",
            "loss: 1.318413  [    0/100000]\n",
            "loss: 1.445293  [ 5000/100000]\n",
            "loss: 1.368365  [10000/100000]\n",
            "loss: 1.836744  [15000/100000]\n",
            "loss: 2.129318  [20000/100000]\n",
            "loss: 3.977601  [25000/100000]\n",
            "loss: 1.993725  [30000/100000]\n",
            "loss: 2.345622  [35000/100000]\n",
            "loss: 1.225492  [40000/100000]\n",
            "loss: 1.680490  [45000/100000]\n",
            "loss: 0.570352  [50000/100000]\n",
            "loss: 1.641143  [55000/100000]\n",
            "loss: 1.714395  [60000/100000]\n",
            "loss: 2.987382  [65000/100000]\n",
            "loss: 2.083764  [70000/100000]\n",
            "loss: 2.247634  [75000/100000]\n",
            "loss: 1.348528  [80000/100000]\n",
            "loss: 3.443050  [85000/100000]\n",
            "loss: 4.160586  [90000/100000]\n",
            "loss: 2.582265  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 46.3%, Avg loss: 2.303190 \n",
            "\n",
            "Epoch 5\n",
            "loss: 2.021904  [    0/100000]\n",
            "loss: 1.979479  [ 5000/100000]\n",
            "loss: 1.977341  [10000/100000]\n",
            "loss: 1.676073  [15000/100000]\n",
            "loss: 2.826826  [20000/100000]\n",
            "loss: 0.761668  [25000/100000]\n",
            "loss: 2.485781  [30000/100000]\n",
            "loss: 3.360642  [35000/100000]\n",
            "loss: 3.168531  [40000/100000]\n",
            "loss: 2.910441  [45000/100000]\n",
            "loss: 0.625783  [50000/100000]\n",
            "loss: 1.033042  [55000/100000]\n",
            "loss: 1.285740  [60000/100000]\n",
            "loss: 1.826365  [65000/100000]\n",
            "loss: 1.351530  [70000/100000]\n",
            "loss: 1.169802  [75000/100000]\n",
            "loss: 1.404638  [80000/100000]\n",
            "loss: 1.660028  [85000/100000]\n",
            "loss: 2.741874  [90000/100000]\n",
            "loss: 0.887803  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 48.1%, Avg loss: 2.205971 \n",
            "\n",
            "Epoch 6\n",
            "loss: 1.830695  [    0/100000]\n",
            "loss: 2.404146  [ 5000/100000]\n",
            "loss: 2.955747  [10000/100000]\n",
            "loss: 2.600758  [15000/100000]\n",
            "loss: 0.715621  [20000/100000]\n",
            "loss: 1.596909  [25000/100000]\n",
            "loss: 3.121907  [30000/100000]\n",
            "loss: 0.900218  [35000/100000]\n",
            "loss: 3.105437  [40000/100000]\n",
            "loss: 0.785861  [45000/100000]\n",
            "loss: 2.039596  [50000/100000]\n",
            "loss: 1.056668  [55000/100000]\n",
            "loss: 3.024127  [60000/100000]\n",
            "loss: 1.015118  [65000/100000]\n",
            "loss: 1.109421  [70000/100000]\n",
            "loss: 2.727987  [75000/100000]\n",
            "loss: 2.049613  [80000/100000]\n",
            "loss: 3.174128  [85000/100000]\n",
            "loss: 2.366056  [90000/100000]\n",
            "loss: 2.544982  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 49.3%, Avg loss: 2.182806 \n",
            "\n",
            "Epoch 7\n",
            "loss: 1.451110  [    0/100000]\n",
            "loss: 2.310764  [ 5000/100000]\n",
            "loss: 2.957071  [10000/100000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-116f040b3b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {i+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_model_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-8edb1dd86951>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kdRvbT8CCzC"
      },
      "source": [
        "#### Run the 2nd cell in case you want to start training from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LUuap5RD3Te9",
        "outputId": "df060343-9b28-4f07-d2d6-048cd2a199cc"
      },
      "source": [
        "model_C = model_C(pretrained=False, progress=True)\n",
        "model_C = model_C.to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer_model_C = torch.optim.Adam(model_C.parameters(), lr=0.0001)\n",
        "\n",
        "es =  EarlyStopping()\n",
        "lrs = LRScheduler(optimizer_model_C)\n",
        "\n",
        "checkpoint_dir = \".\"\n",
        "test_loss = 0\n",
        "epochs = 20\n",
        "for i in range(epochs):\n",
        "    print(f\"Epoch {i+1}\")\n",
        "    train(trainloader, model_C, loss_fn, optimizer_model_C)\n",
        "    test_loss = test(testloader, model_C, loss_fn)\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': i+1,\n",
        "        'model_state_dict': model_C.state_dict(),\n",
        "        'optimizer_state_dict': optimizer_model_C.state_dict(),\n",
        "        'loss': test_loss\n",
        "        }, checkpoint_dir+'/%04d-model_C-model.ckpt' %i)\n",
        "    \n",
        "    lrs(test_loss)\n",
        "    es(test_loss)\n",
        "    if es.early_stop:\n",
        "      break\n",
        "\n",
        "\n",
        "torch.save({\n",
        "        'epoch': epochs,\n",
        "        'model_state_dict': model_C.state_dict(),\n",
        "        'optimizer_state_dict': optimizer_model_C.state_dict(),\n",
        "        'loss': test_loss\n",
        "        }, checkpoint_dir+'/final-model_C-model.ckpt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 5.431168  [    0/100000]\n",
            "loss: 5.120161  [ 5000/100000]\n",
            "loss: 5.820371  [10000/100000]\n",
            "loss: 5.439474  [15000/100000]\n",
            "loss: 5.282197  [20000/100000]\n",
            "loss: 4.955653  [25000/100000]\n",
            "loss: 5.394137  [30000/100000]\n",
            "loss: 5.057934  [35000/100000]\n",
            "loss: 3.323185  [40000/100000]\n",
            "loss: 3.904299  [45000/100000]\n",
            "loss: 3.762244  [50000/100000]\n",
            "loss: 3.902979  [55000/100000]\n",
            "loss: 4.369588  [60000/100000]\n",
            "loss: 3.908147  [65000/100000]\n",
            "loss: 4.588083  [70000/100000]\n",
            "loss: 4.433502  [75000/100000]\n",
            "loss: 4.081896  [80000/100000]\n",
            "loss: 3.475511  [85000/100000]\n",
            "loss: 3.944045  [90000/100000]\n",
            "loss: 4.103803  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 17.0%, Avg loss: 3.794770 \n",
            "\n",
            "Epoch 2\n",
            "loss: 3.084594  [    0/100000]\n",
            "loss: 4.184231  [ 5000/100000]\n",
            "loss: 4.335943  [10000/100000]\n",
            "loss: 4.466634  [15000/100000]\n",
            "loss: 4.734660  [20000/100000]\n",
            "loss: 4.583914  [25000/100000]\n",
            "loss: 4.740537  [30000/100000]\n",
            "loss: 4.327954  [35000/100000]\n",
            "loss: 4.031455  [40000/100000]\n",
            "loss: 3.033637  [45000/100000]\n",
            "loss: 2.783329  [50000/100000]\n",
            "loss: 3.199600  [55000/100000]\n",
            "loss: 3.031535  [60000/100000]\n",
            "loss: 3.208496  [65000/100000]\n",
            "loss: 3.707250  [70000/100000]\n",
            "loss: 2.839703  [75000/100000]\n",
            "loss: 2.770879  [80000/100000]\n",
            "loss: 2.907939  [85000/100000]\n",
            "loss: 3.243369  [90000/100000]\n",
            "loss: 3.019264  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 23.5%, Avg loss: 3.418854 \n",
            "\n",
            "Epoch 3\n",
            "loss: 2.702632  [    0/100000]\n",
            "loss: 2.821712  [ 5000/100000]\n",
            "loss: 4.342077  [10000/100000]\n",
            "loss: 3.121122  [15000/100000]\n",
            "loss: 3.371972  [20000/100000]\n",
            "loss: 3.390469  [25000/100000]\n",
            "loss: 2.292783  [30000/100000]\n",
            "loss: 4.340801  [35000/100000]\n",
            "loss: 4.132340  [40000/100000]\n",
            "loss: 3.773715  [45000/100000]\n",
            "loss: 3.080702  [50000/100000]\n",
            "loss: 2.713479  [55000/100000]\n",
            "loss: 2.694438  [60000/100000]\n",
            "loss: 4.108390  [65000/100000]\n",
            "loss: 4.460870  [70000/100000]\n",
            "loss: 3.178798  [75000/100000]\n",
            "loss: 3.186082  [80000/100000]\n",
            "loss: 2.979270  [85000/100000]\n",
            "loss: 4.062338  [90000/100000]\n",
            "loss: 2.590497  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 27.3%, Avg loss: 3.203748 \n",
            "\n",
            "Epoch 4\n",
            "loss: 3.871344  [    0/100000]\n",
            "loss: 2.710602  [ 5000/100000]\n",
            "loss: 2.700644  [10000/100000]\n",
            "loss: 3.368247  [15000/100000]\n",
            "loss: 2.599074  [20000/100000]\n",
            "loss: 3.694396  [25000/100000]\n",
            "loss: 3.230216  [30000/100000]\n",
            "loss: 3.188237  [35000/100000]\n",
            "loss: 3.377595  [40000/100000]\n",
            "loss: 3.449845  [45000/100000]\n",
            "loss: 5.249126  [50000/100000]\n",
            "loss: 3.308137  [55000/100000]\n",
            "loss: 2.683297  [60000/100000]\n",
            "loss: 1.443798  [65000/100000]\n",
            "loss: 2.348850  [70000/100000]\n",
            "loss: 2.164645  [75000/100000]\n",
            "loss: 3.315135  [80000/100000]\n",
            "loss: 3.555871  [85000/100000]\n",
            "loss: 2.768468  [90000/100000]\n",
            "loss: 1.991463  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 30.4%, Avg loss: 3.045138 \n",
            "\n",
            "Epoch 5\n",
            "loss: 2.868545  [    0/100000]\n",
            "loss: 2.086833  [ 5000/100000]\n",
            "loss: 0.962587  [10000/100000]\n",
            "loss: 3.470753  [15000/100000]\n",
            "loss: 2.870860  [20000/100000]\n",
            "loss: 2.219310  [25000/100000]\n",
            "loss: 2.390667  [30000/100000]\n",
            "loss: 4.065463  [35000/100000]\n",
            "loss: 3.313550  [40000/100000]\n",
            "loss: 4.722373  [45000/100000]\n",
            "loss: 1.288795  [50000/100000]\n",
            "loss: 2.446925  [55000/100000]\n",
            "loss: 2.481908  [60000/100000]\n",
            "loss: 1.989157  [65000/100000]\n",
            "loss: 4.449033  [70000/100000]\n",
            "loss: 2.602186  [75000/100000]\n",
            "loss: 2.307384  [80000/100000]\n",
            "loss: 3.050954  [85000/100000]\n",
            "loss: 3.642900  [90000/100000]\n",
            "loss: 2.088301  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 32.8%, Avg loss: 2.917266 \n",
            "\n",
            "Epoch 6\n",
            "loss: 1.698245  [    0/100000]\n",
            "loss: 2.089696  [ 5000/100000]\n",
            "loss: 2.336994  [10000/100000]\n",
            "loss: 1.224598  [15000/100000]\n",
            "loss: 4.640043  [20000/100000]\n",
            "loss: 4.718946  [25000/100000]\n",
            "loss: 2.323180  [30000/100000]\n",
            "loss: 3.307946  [35000/100000]\n",
            "loss: 3.768695  [40000/100000]\n",
            "loss: 3.392585  [45000/100000]\n",
            "loss: 1.618393  [50000/100000]\n",
            "loss: 2.852092  [55000/100000]\n",
            "loss: 3.100046  [60000/100000]\n",
            "loss: 2.793909  [65000/100000]\n",
            "loss: 1.260372  [70000/100000]\n",
            "loss: 2.700094  [75000/100000]\n",
            "loss: 2.406126  [80000/100000]\n",
            "loss: 2.414114  [85000/100000]\n",
            "loss: 2.377763  [90000/100000]\n",
            "loss: 3.571749  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 34.2%, Avg loss: 2.865678 \n",
            "\n",
            "Epoch 7\n",
            "loss: 2.959126  [    0/100000]\n",
            "loss: 2.578217  [ 5000/100000]\n",
            "loss: 2.138145  [10000/100000]\n",
            "loss: 1.642358  [15000/100000]\n",
            "loss: 2.018202  [20000/100000]\n",
            "loss: 2.561409  [25000/100000]\n",
            "loss: 1.771772  [30000/100000]\n",
            "loss: 1.660763  [35000/100000]\n",
            "loss: 0.828772  [40000/100000]\n",
            "loss: 2.445624  [45000/100000]\n",
            "loss: 2.756997  [50000/100000]\n",
            "loss: 2.702670  [55000/100000]\n",
            "loss: 4.659305  [60000/100000]\n",
            "loss: 1.482111  [65000/100000]\n",
            "loss: 2.632860  [70000/100000]\n",
            "loss: 3.123225  [75000/100000]\n",
            "loss: 2.032603  [80000/100000]\n",
            "loss: 1.344870  [85000/100000]\n",
            "loss: 3.362826  [90000/100000]\n",
            "loss: 2.266029  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 36.1%, Avg loss: 2.809599 \n",
            "\n",
            "Epoch 8\n",
            "loss: 2.655923  [    0/100000]\n",
            "loss: 1.888939  [ 5000/100000]\n",
            "loss: 1.610345  [10000/100000]\n",
            "loss: 2.149460  [15000/100000]\n",
            "loss: 1.480332  [20000/100000]\n",
            "loss: 3.262441  [25000/100000]\n",
            "loss: 2.480495  [30000/100000]\n",
            "loss: 2.532273  [35000/100000]\n",
            "loss: 3.144121  [40000/100000]\n",
            "loss: 2.529756  [45000/100000]\n",
            "loss: 2.064263  [50000/100000]\n",
            "loss: 2.175350  [55000/100000]\n",
            "loss: 3.010158  [60000/100000]\n",
            "loss: 1.713431  [65000/100000]\n",
            "loss: 1.619930  [70000/100000]\n",
            "loss: 2.002298  [75000/100000]\n",
            "loss: 1.395291  [80000/100000]\n",
            "loss: 2.463752  [85000/100000]\n",
            "loss: 3.542889  [90000/100000]\n",
            "loss: 2.446020  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 36.3%, Avg loss: 2.772601 \n",
            "\n",
            "Epoch 9\n",
            "loss: 2.306240  [    0/100000]\n",
            "loss: 1.752823  [ 5000/100000]\n",
            "loss: 2.152354  [10000/100000]\n",
            "loss: 2.492409  [15000/100000]\n",
            "loss: 2.647715  [20000/100000]\n",
            "loss: 1.000475  [25000/100000]\n",
            "loss: 2.366716  [30000/100000]\n",
            "loss: 2.937325  [35000/100000]\n",
            "loss: 1.301488  [40000/100000]\n",
            "loss: 3.106374  [45000/100000]\n",
            "loss: 2.908293  [50000/100000]\n",
            "loss: 1.451662  [55000/100000]\n",
            "loss: 3.416603  [60000/100000]\n",
            "loss: 2.613687  [65000/100000]\n",
            "loss: 2.001985  [70000/100000]\n",
            "loss: 2.412526  [75000/100000]\n",
            "loss: 0.862247  [80000/100000]\n",
            "loss: 2.235706  [85000/100000]\n",
            "loss: 1.871221  [90000/100000]\n",
            "loss: 3.103658  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 37.5%, Avg loss: 2.754966 \n",
            "\n",
            "Epoch 10\n",
            "loss: 2.841287  [    0/100000]\n",
            "loss: 0.967641  [ 5000/100000]\n",
            "loss: 1.741502  [10000/100000]\n",
            "loss: 1.705149  [15000/100000]\n",
            "loss: 1.311871  [20000/100000]\n",
            "loss: 4.236475  [25000/100000]\n",
            "loss: 3.245167  [30000/100000]\n",
            "loss: 1.972038  [35000/100000]\n",
            "loss: 1.943568  [40000/100000]\n",
            "loss: 2.422792  [45000/100000]\n",
            "loss: 1.318942  [50000/100000]\n",
            "loss: 2.272992  [55000/100000]\n",
            "loss: 2.280675  [60000/100000]\n",
            "loss: 1.941553  [65000/100000]\n",
            "loss: 4.092613  [70000/100000]\n",
            "loss: 2.441421  [75000/100000]\n",
            "loss: 1.556936  [80000/100000]\n",
            "loss: 3.315942  [85000/100000]\n",
            "loss: 0.746265  [90000/100000]\n",
            "loss: 1.116104  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 37.3%, Avg loss: 2.768611 \n",
            "\n",
            "Epoch 11\n",
            "loss: 3.087799  [    0/100000]\n",
            "loss: 2.403718  [ 5000/100000]\n",
            "loss: 1.923145  [10000/100000]\n",
            "loss: 3.531651  [15000/100000]\n",
            "loss: 2.362792  [20000/100000]\n",
            "loss: 3.417973  [25000/100000]\n",
            "loss: 1.355358  [30000/100000]\n",
            "loss: 2.751997  [35000/100000]\n",
            "loss: 1.559448  [40000/100000]\n",
            "loss: 0.670010  [45000/100000]\n",
            "loss: 2.644296  [50000/100000]\n",
            "loss: 1.812928  [55000/100000]\n",
            "loss: 2.961466  [60000/100000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-fc8c1871e915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {i+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_model_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-8edb1dd86951>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-624d36406c8f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-624d36406c8f>\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-624d36406c8f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# CUBS 2 -> CUBS 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcubs2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcubs1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8cedfdc03880>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m       \u001b[0mx_1_2_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCB1_Sim1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_1_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8cedfdc03880>\u001b[0m in \u001b[0;36mCB1_Sim1\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0msim_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}