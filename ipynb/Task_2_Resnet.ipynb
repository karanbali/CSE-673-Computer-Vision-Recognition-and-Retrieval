{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_2_Resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EA7VaH7Ydxy"
      },
      "source": [
        "# Task 2: ResNet-18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm3JXBTYMGnx"
      },
      "source": [
        "### Import Dependencies and download \"Tiny-ImageNet-200\" dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7Co0iJiwbjk",
        "outputId": "d0545e3c-e9e7-4de9-b512-d0272a230ffb"
      },
      "source": [
        "# Mounting Google drive for loading the checkpoint.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cd gdrive/MyDrive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeloaBMkxvhi",
        "outputId": "c6efcbc3-8c26-4990-badc-d54a86d1bcb9"
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip && ls tiny-imagenet-200\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import torchvision.models as models\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "cuda = torch.device('cuda') \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-05 19:18:57--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  37.3MB/s    in 7.8s    \n",
            "\n",
            "2021-11-05 19:19:05 (30.2 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n",
            "test  train  val  wnids.txt  words.txt\n",
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzDGwZoxMUHX"
      },
      "source": [
        "### Preprocessing: Collate all image's path address & labels as a input to custom pytorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HVW1-sJyWsJ"
      },
      "source": [
        "file_list = []\n",
        "\n",
        "\n",
        "for folder in os.listdir('./tiny-imagenet-200/train/'):\n",
        "\n",
        "\n",
        "  label = folder \n",
        "  for file in os.listdir('./tiny-imagenet-200/train/' + folder + '/images/'):\n",
        "    file_dir = './tiny-imagenet-200/train/' + folder + '/images/' + file\n",
        "\n",
        "    file_list.append((file_dir))\n",
        "\n",
        "with open('./tiny-imagenet-200/wnids.txt',) as f:\n",
        "\n",
        "  id_list = {}\n",
        "  read_data = f.readlines()\n",
        "  for i, val in enumerate(read_data):\n",
        "    id_list[val.replace('\\n', '')] = i\n",
        "\n",
        "\n",
        "test_list = []\n",
        "test_id = {}\n",
        "with open('./tiny-imagenet-200/val/val_annotations.txt', 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    file, label = line.split()[0:2]\n",
        "    file_dir = './tiny-imagenet-200/val/images/' + file\n",
        "\n",
        "    test_list.append((file_dir))\n",
        "    test_id[file] = label"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQwYYGpPNdu-"
      },
      "source": [
        "### Custom Pytorch datatset for training images of \"Tiny-ImageNet-200\" dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EytwpRzykLF"
      },
      "source": [
        "\n",
        "class TrainTinyImageNetDataset(Dataset):\n",
        "    def __init__(self, f_list, id, transform=None):\n",
        "\n",
        "        self.filenames = f_list\n",
        "        self.transform = transform\n",
        "        self.id_dict = id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = self.filenames[idx]\n",
        "        image = None\n",
        "       \n",
        "        with open(img_path, 'rb') as f:\n",
        "          image = Image.open(f)\n",
        "          image =  image.convert('RGB')\n",
        "          \n",
        "        \n",
        "       \n",
        "\n",
        "        label = self.id_dict[img_path.split('/')[-1].split('.')[0].split('_')[0]]\n",
        "       \n",
        "\n",
        "        if self.transform is not None:\n",
        "\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, label\n",
        "\n",
        "\n",
        "class TrainSet(TrainTinyImageNetDataset):\n",
        "  \n",
        "    def __init__(self, f_list, id, transform=None):\n",
        "\n",
        "        super(TrainSet, self).__init__(f_list, id, transform=transform)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2VBY3rZNpiS"
      },
      "source": [
        "### Custom Pytorch datatset for testing images of \"Tiny-ImageNet-200\" dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KOWAGrxy2-E"
      },
      "source": [
        "class TestTinyImageNetDataset(Dataset):\n",
        "    def __init__(self, t_list, id, cls_id, transform=None):\n",
        "        self.filenames = t_list\n",
        "        self.transform = transform\n",
        "        self.id_dict = id\n",
        "        self.cls_id = cls_id\n",
        "       \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.filenames[idx]\n",
        "        image = None\n",
        "       \n",
        "        with open(img_path, 'rb') as f:\n",
        "          image = Image.open(f)\n",
        "          image =  image.convert('RGB')\n",
        "    \n",
        "        label = self.cls_id[self.id_dict[img_path.split('/')[-1]]]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "       "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFlNKw85ON_7"
      },
      "source": [
        "### CUBS Block 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5arFr_LzNJd"
      },
      "source": [
        "class CUBS1(nn.Module):\n",
        "  def __init__(self, channels_in, n_in):\n",
        "      super(CUBS1, self).__init__()\n",
        "      self.channels_in = channels_in\n",
        "      self.n_in = n_in\n",
        "      self.dense_1_1 = nn.Linear(channels_in,n_in)\n",
        "      self.dense_1_2 = nn.Linear(channels_in,n_in)\n",
        "      self.dense_1_3 = nn.Linear(channels_in,n_in)\n",
        "      self.dense_2 = nn.Linear(n_in,channels_in)\n",
        "      self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    \n",
        "\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "      self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def CB1_Sim1(self, a, b):\n",
        "    a_norm = torch.nn.functional.normalize(a, dim=2)\n",
        "    b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "    sim_matrix = torch.matmul(a_norm[0].T, b_norm[0])\n",
        "    sim_matrix = sim_matrix.reshape((1,self.n_in,self.n_in))\n",
        "\n",
        "\n",
        "    for i in range(1,a.shape[0]):\n",
        "  \n",
        "      mul = torch.matmul(a_norm[i].T, b_norm[i]) \n",
        "      mul = mul.reshape((1,self.n_in,self.n_in))\n",
        "      sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "      \n",
        "\n",
        "    \n",
        "\n",
        "    return sim_matrix\n",
        "\n",
        "\n",
        "  def CB1_Sim2(self, a, b):\n",
        "    b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "    sim_matrix = torch.matmul(a[0], b_norm[0].T)\n",
        "    sim_matrix = sim_matrix.reshape((1,1,self.n_in))\n",
        "\n",
        "\n",
        "    for i in range(1,a.shape[0]):\n",
        "      mul = torch.matmul(a[i], b_norm[i].T)\n",
        "      mul = mul.reshape((1,1,self.n_in))\n",
        "      sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "\n",
        "    return sim_matrix\n",
        "\n",
        "  def CB1_Softmax(self, a):\n",
        "    out_matrix = nn.Softmax(dim=1)(a[0])\n",
        "    out_matrix = out_matrix.reshape((1,self.n_in,self.n_in))\n",
        "\n",
        "    for i in range(1,a.shape[0]):\n",
        "      sim = nn.Softmax(dim=1)(a[i])\n",
        "      sim = sim.reshape((1,self.n_in,self.n_in))\n",
        "      out_matrix = torch.vstack((out_matrix,sim))\n",
        "\n",
        "    return out_matrix\n",
        "\n",
        "  def CB1_Channel(self, a, b):\n",
        "    out_matrix = b[0] * a[0].unsqueeze(dim=-1). unsqueeze(dim=-1)\n",
        "\n",
        "    for i in range(1,a.shape[0]): \n",
        "      mul = b[i] * a[i].unsqueeze(dim=-1). unsqueeze(dim=-1)\n",
        "      out_matrix = torch.vstack((out_matrix,mul))\n",
        "\n",
        "    return out_matrix\n",
        "\n",
        "      \n",
        "  \n",
        "\n",
        "  def forward(self, x):\n",
        "      x_pool = self.avgpool(x)\n",
        "      x_pool = torch.reshape(x_pool,(x.shape[0],1,x.shape[1]))\n",
        "\n",
        "     \n",
        "\n",
        "      x_1_1 = self.dense_1_1(x_pool)\n",
        "     \n",
        "      \n",
        "      x_1_1 = self.relu(x_1_1)\n",
        "\n",
        "      x_1_2 = self.dense_1_2(x_pool)\n",
        "      x_1_2 = self.relu(x_1_2)\n",
        "\n",
        "      x_1_3 = self.dense_1_3(x_pool)\n",
        "      x_1_3 = self.relu(x_1_3)\n",
        "\n",
        "     \n",
        "      x_1_2_sim = self.CB1_Sim1(x_1_1, x_1_2)\n",
        "\n",
        "\n",
        "            \n",
        "      x_1_2_softmax = self.CB1_Softmax(x_1_2_sim)\n",
        "\n",
        "  \n",
        "      x_1_2_3_sim = self.CB1_Sim2(x_1_3, x_1_2_softmax)\n",
        "      \n",
        "      x_2 = self.dense_2(x_1_2_3_sim)\n",
        "      x_2 = self.relu(x_2)\n",
        "\n",
        "      x_concat_1 = torch.add(x_2, x_pool)\n",
        "      x_sig = self.sig(x_concat_1)\n",
        "\n",
        "\n",
        "      x_out = self.CB1_Channel(x_sig, x)\n",
        "      return x_out\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYc-zspuOS89"
      },
      "source": [
        "### CUBS Block 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EJGDFNEzXda"
      },
      "source": [
        "\n",
        "class CUBS2(nn.Module):\n",
        "  def __init__(self, channels_in, n_in):\n",
        "      super(CUBS2, self).__init__()\n",
        "      self.channels_in = channels_in\n",
        "      self.n_in = n_in\n",
        "\n",
        "\n",
        "      self.conv_1_1 = nn.Conv2d(channels_in, 1, kernel_size=1)\n",
        "      self.conv_1_2 = nn.Conv2d(channels_in, 1, kernel_size=1)\n",
        "      self.conv_1_3 = nn.Conv2d(channels_in, 1, kernel_size=1)\n",
        "      \n",
        "   \n",
        "      \n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "      self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def CB2_Sim1(self, a, b):\n",
        "\n",
        "      a = torch.flatten(a, start_dim=2, end_dim=3)    \n",
        "      b = torch.flatten(b, start_dim=2, end_dim=3)\n",
        "\n",
        "      a_norm = torch.nn.functional.normalize(a, dim=2)\n",
        "      b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "      sim_matrix = torch.matmul(a_norm[0].T, b_norm[0])\n",
        "      sim_matrix = sim_matrix.reshape((1,a.shape[2],a.shape[2]))\n",
        "\n",
        "\n",
        "      for i in range(1,a.shape[0]):\n",
        "    \n",
        "        mul = torch.matmul(a_norm[i].T, b_norm[i]) \n",
        "        mul = mul.reshape((1,a.shape[2],a.shape[2]))\n",
        "        sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "        \n",
        "\n",
        "      return sim_matrix\n",
        "\n",
        "\n",
        "  def CB2_Sim2(self, a, b):\n",
        "\n",
        "      a = torch.flatten(a, start_dim=2, end_dim=3)\n",
        "      b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "      sim_matrix = torch.matmul(a[0], b_norm[0].T)\n",
        "      sim_matrix = sim_matrix.reshape((1,1,a.shape[2]))\n",
        "\n",
        "\n",
        "      for i in range(1,a.shape[0]):\n",
        "        mul = torch.matmul(a[i], b_norm[i].T)\n",
        "        mul = mul.reshape((1,1,a.shape[2]))\n",
        "        sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "\n",
        "      return sim_matrix\n",
        "\n",
        "\n",
        "  def CB2_Softmax(self, a):\n",
        "      out_matrix = nn.Softmax(dim=1)(a[0])\n",
        "      out_matrix = out_matrix.reshape((1,a.shape[2],a.shape[2]))\n",
        "\n",
        "      for i in range(1,a.shape[0]):\n",
        "        sim = nn.Softmax(dim=1)(a[i])\n",
        "        sim = sim.reshape((1,a.shape[2],a.shape[2]))\n",
        "        out_matrix = torch.vstack((out_matrix,sim))\n",
        "\n",
        "      return out_matrix\n",
        "\n",
        "  \n",
        "\n",
        "  def bmul(self, vec, mat, axis=0):\n",
        "      mat = mat.transpose(axis, -1)\n",
        "      return (mat * vec.expand_as(mat)).transpose(axis, -1)\n",
        "\n",
        "  def CB1_Pixel(self, a, b):\n",
        "      a = torch.reshape(a, (a.shape[0],b.shape[2],b.shape[3]))\n",
        "    \n",
        "      a_0 = a[0]\n",
        "      b_0 = b[0]\n",
        "      out_matrix = self.bmul(a_0,b_0, axis=2)\n",
        "      out_matrix = out_matrix.reshape((1,b.shape[1],b.shape[2],b.shape[3]))\n",
        "\n",
        "      for i in range(1, a.shape[0]):\n",
        "        ai = a[i]\n",
        "        \n",
        "        bi = b[i]\n",
        "      \n",
        "        mul = self.bmul(ai,bi, axis=2)\n",
        "        mul = mul.reshape((1,b.shape[1],b.shape[2],b.shape[3]))\n",
        "        out_matrix = torch.vstack((out_matrix,mul))\n",
        "\n",
        "      return out_matrix\n",
        "      \n",
        "  def forward(self, x):\n",
        "\n",
        "     \n",
        "      x_1_1 = self.conv_1_1(x)\n",
        "      x_1_1 = self.relu(x_1_1)\n",
        "\n",
        "      x_1_2 = self.conv_1_2(x)\n",
        "      x_1_2 = self.relu(x_1_2)\n",
        "\n",
        "      x_1_3 = self.conv_1_3(x)\n",
        "      x_1_3 = self.relu(x_1_3)\n",
        "\n",
        "     \n",
        "      x_1_2_sim = self.CB2_Sim1(x_1_1, x_1_2)\n",
        "\n",
        "      x_1_2_softmax = self.CB2_Softmax(x_1_2_sim)\n",
        "\n",
        "     \n",
        "      x_1_2_3_sim = self.CB2_Sim2(x_1_3, x_1_2_softmax)\n",
        "      \n",
        "      x_sig = self.sig(x_1_2_3_sim)\n",
        "\n",
        "     \n",
        "      x_out = self.CB1_Pixel(x_sig, x)\n",
        "      \n",
        "      return x_out\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6QmOSHhOYqj"
      },
      "source": [
        "### This section contains Open-Sourced \"ResNet-18\" implementation along with various modifications and CUBS Blocks(1 & 2) experiments mentioned in the assignment.\n",
        "\n",
        "***\n",
        "\n",
        "### I've modified the \"BasicBlock\" of open-sourced ResNet-18 implementations to get new \"BasicBlock_A\", \"BasicBlock_B\" and \"BasicBlock_C\" defining the all 3 different configurations that were given as a task.\n",
        "\n",
        "***\n",
        "\n",
        "### BasicBlock_A : Parallel CUBS 1 & CUBS 2\n",
        "### BasicBlock_B : CUBS 1 -> CUBS 2\n",
        "### BasicBlock_C : CUBS 2 -> CUBS 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaKzw2yczttS"
      },
      "source": [
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
        "           'wide_resnet50_2', 'wide_resnet101_2']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class BasicBlock_A(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock_A, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.cubs1 = CUBS1(planes, 30)\n",
        "        self.cubs2 = CUBS2(planes, 30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # Parallel CUBS 1 & CUBS 2\n",
        "        out_cubs1 = self.cubs1(out)\n",
        "        out_cubs2 = self.cubs2(out)\n",
        "\n",
        "        out = out_cubs1 + out_cubs2\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class BasicBlock_B(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock_B, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.cubs1 = CUBS1(planes, 30)\n",
        "        self.cubs2 = CUBS2(planes, 30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # CUBS 1 -> CUBS 2\n",
        "        out = self.cubs1(out)\n",
        "        out = self.cubs2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class BasicBlock_C(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock_C, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.cubs1 = CUBS1(planes, 30)\n",
        "        self.cubs2 = CUBS2(planes, 30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # CUBS 2 -> CUBS 1\n",
        "        out = self.cubs2(out)\n",
        "        out = self.cubs1(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=200, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWAyWPSrV7xg"
      },
      "source": [
        "### Defining 4 different models for vanilla ResNet-18, Model_A, Model_B & Model_C with different variations of \"BasicBlock\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLRRshHh0fOG"
      },
      "source": [
        "def resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "    \n",
        "\n",
        "def model_A(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock_A, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "    \n",
        "\n",
        "def model_B(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock_B, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "    \n",
        "\n",
        "def model_C(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock_C, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t1FDzZyWSXF"
      },
      "source": [
        "### Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGaWrdlCzzh2"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      \n",
        "        X, y = X.to(device), y.long().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        torch.set_grad_enabled(True)\n",
        "        \n",
        "        pred = model(X).float()\n",
        "       \n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "       \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    \n",
        "        if batch % 1000 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv7QwhDXWXOV"
      },
      "source": [
        "### Testing Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pts-sMZ6z86K"
      },
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "          \n",
        "            X, y = X.to(device), y.long().to(device)\n",
        "            torch.set_grad_enabled(False)\n",
        "            pred = model(X).float()\n",
        "       \n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-YM-OZXWbvU"
      },
      "source": [
        "### Defining \"Learning Rate Scheduler\" & \"Early stopping mechanism\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irq8901N-Jo7"
      },
      "source": [
        "class LRScheduler():\n",
        "  \n",
        "    def __init__(\n",
        "        self, optimizer, patience=5, min_lr=1e-7, factor=0.75\n",
        "    ):\n",
        "        \n",
        "        self.optimizer = optimizer\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
        "                self.optimizer,\n",
        "                mode='min',\n",
        "                patience=self.patience,\n",
        "                factor=self.factor,\n",
        "                min_lr=self.min_lr,\n",
        "                verbose=True\n",
        "            )\n",
        "    def __call__(self, val_loss):\n",
        "        self.scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "class EarlyStopping():\n",
        "   \n",
        "    def __init__(self, patience=10, min_delta=0):\n",
        "      \n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss == None:\n",
        "            self.best_loss = val_loss\n",
        "        elif self.best_loss - val_loss > self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        elif self.best_loss - val_loss < self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe3EI69a7n3l"
      },
      "source": [
        "### Instantiating Dataset loaders for training & testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4GR1wYJ-TUz"
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "trans = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "trainset = TrainSet(f_list=file_list,id=id_list, transform=trans)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=5, shuffle=True, num_workers=4)\n",
        "\n",
        "trans_test = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "testset = TestTinyImageNetDataset(t_list=test_list,id=test_id, cls_id =id_list,  transform=trans_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False, num_workers=4)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLRr5OJPXUPH"
      },
      "source": [
        "### Instantiating & training & checkpoint vanilla \"ResNet-18\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOfZQRic_5ip"
      },
      "source": [
        "#### There are 2 cells for ResNet that are given below.\n",
        "#### Run the 1st cell in case you want to load a checkpoint & resume training.\n",
        "#### Else Run the 2nd cell in case you want to start training from scratch.\n",
        "\n",
        "#### **NOTE: Make sure to change the path of loading the checkpoint in 1st cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sOMvWOSefBec",
        "outputId": "3d02a7fd-dff9-4f7b-cdca-4b7505ec6435"
      },
      "source": [
        "\n",
        "resnet18 = resnet18(pretrained=False, progress=True)\n",
        "resnet18 = resnet18.to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer_resnet18 = torch.optim.Adam(resnet18.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "# **NOTE: Make sure to change the path of loading the checkpoint in 1st cell**\n",
        "checkpoint = torch.load('gdrive/MyDrive/trained-resnet-model.ckpt')\n",
        "\n",
        "\n",
        "resnet18.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer_resnet18.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch'] + 1\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "\n",
        "es =  EarlyStopping()\n",
        "lrs = LRScheduler(optimizer_resnet18)\n",
        "\n",
        "checkpoint_dir = \".\"\n",
        "test_loss = 0\n",
        "epochs = 20\n",
        "for i in range(epochs):\n",
        "    print(f\"Epoch {i+1}\")\n",
        "    train(trainloader, resnet18, loss_fn, optimizer_resnet18)\n",
        "    test_loss = test(testloader, resnet18, loss_fn)\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': i+1,\n",
        "        'model_state_dict': resnet18.state_dict(),\n",
        "        'optimizer_state_dict': optimizer_resnet18.state_dict(),\n",
        "        'loss': test_loss\n",
        "        }, checkpoint_dir+'/%04d-resnet18-model.ckpt' %i)\n",
        "    \n",
        "    lrs(test_loss)\n",
        "    es(test_loss)\n",
        "    if es.early_stop:\n",
        "      break\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 5.641243  [    0/100000]\n",
            "loss: 4.444726  [ 5000/100000]\n",
            "loss: 2.838123  [10000/100000]\n",
            "loss: 5.427865  [15000/100000]\n",
            "loss: 4.558853  [20000/100000]\n",
            "loss: 3.328851  [25000/100000]\n",
            "loss: 3.490523  [30000/100000]\n",
            "loss: 3.316442  [35000/100000]\n",
            "loss: 1.147036  [40000/100000]\n",
            "loss: 3.911994  [45000/100000]\n",
            "loss: 3.627628  [50000/100000]\n",
            "loss: 3.303799  [55000/100000]\n",
            "loss: 2.895082  [60000/100000]\n",
            "loss: 2.163172  [65000/100000]\n",
            "loss: 3.185191  [70000/100000]\n",
            "loss: 3.009372  [75000/100000]\n",
            "loss: 4.382486  [80000/100000]\n",
            "loss: 1.330630  [85000/100000]\n",
            "loss: 3.935147  [90000/100000]\n",
            "loss: 1.544276  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 37.1%, Avg loss: 2.693773 \n",
            "\n",
            "Epoch 2\n",
            "loss: 3.676970  [    0/100000]\n",
            "loss: 2.760877  [ 5000/100000]\n",
            "loss: 2.213978  [10000/100000]\n",
            "loss: 3.101293  [15000/100000]\n",
            "loss: 3.221472  [20000/100000]\n",
            "loss: 3.131885  [25000/100000]\n",
            "loss: 3.477355  [30000/100000]\n",
            "loss: 2.622531  [35000/100000]\n",
            "loss: 2.585910  [40000/100000]\n",
            "loss: 1.917548  [45000/100000]\n",
            "loss: 1.958019  [50000/100000]\n",
            "loss: 2.530879  [55000/100000]\n",
            "loss: 2.833067  [60000/100000]\n",
            "loss: 3.281213  [65000/100000]\n",
            "loss: 2.354267  [70000/100000]\n",
            "loss: 0.958555  [75000/100000]\n",
            "loss: 3.114559  [80000/100000]\n",
            "loss: 1.674775  [85000/100000]\n",
            "loss: 3.188629  [90000/100000]\n",
            "loss: 1.792736  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 42.0%, Avg loss: 2.468586 \n",
            "\n",
            "Epoch 3\n",
            "loss: 2.406596  [    0/100000]\n",
            "loss: 3.369313  [ 5000/100000]\n",
            "loss: 1.955431  [10000/100000]\n",
            "loss: 2.986840  [15000/100000]\n",
            "loss: 2.691358  [20000/100000]\n",
            "loss: 2.863421  [25000/100000]\n",
            "loss: 2.254707  [30000/100000]\n",
            "loss: 1.680440  [35000/100000]\n",
            "loss: 1.885282  [40000/100000]\n",
            "loss: 1.922555  [45000/100000]\n",
            "loss: 1.823931  [50000/100000]\n",
            "loss: 1.571446  [55000/100000]\n",
            "loss: 1.923226  [60000/100000]\n",
            "loss: 2.743966  [65000/100000]\n",
            "loss: 2.127984  [70000/100000]\n",
            "loss: 2.317450  [75000/100000]\n",
            "loss: 1.946357  [80000/100000]\n",
            "loss: 3.784421  [85000/100000]\n",
            "loss: 2.418386  [90000/100000]\n",
            "loss: 3.208706  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 45.7%, Avg loss: 2.265041 \n",
            "\n",
            "Epoch 4\n",
            "loss: 2.195478  [    0/100000]\n",
            "loss: 1.851701  [ 5000/100000]\n",
            "loss: 2.003200  [10000/100000]\n",
            "loss: 2.123007  [15000/100000]\n",
            "loss: 2.662187  [20000/100000]\n",
            "loss: 2.379499  [25000/100000]\n",
            "loss: 2.137135  [30000/100000]\n",
            "loss: 1.718080  [35000/100000]\n",
            "loss: 2.359005  [40000/100000]\n",
            "loss: 2.906638  [45000/100000]\n",
            "loss: 2.419445  [50000/100000]\n",
            "loss: 3.340575  [55000/100000]\n",
            "loss: 2.266289  [60000/100000]\n",
            "loss: 2.027633  [65000/100000]\n",
            "loss: 1.747545  [70000/100000]\n",
            "loss: 1.561652  [75000/100000]\n",
            "loss: 1.232508  [80000/100000]\n",
            "loss: 2.816224  [85000/100000]\n",
            "loss: 1.515517  [90000/100000]\n",
            "loss: 2.475414  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 47.1%, Avg loss: 2.274401 \n",
            "\n",
            "Epoch 5\n",
            "loss: 2.102620  [    0/100000]\n",
            "loss: 1.225416  [ 5000/100000]\n",
            "loss: 2.065248  [10000/100000]\n",
            "loss: 2.568379  [15000/100000]\n",
            "loss: 1.270067  [20000/100000]\n",
            "loss: 0.907852  [25000/100000]\n",
            "loss: 2.221266  [30000/100000]\n",
            "loss: 1.139569  [35000/100000]\n",
            "loss: 2.157382  [40000/100000]\n",
            "loss: 2.959275  [45000/100000]\n",
            "loss: 1.197086  [50000/100000]\n",
            "loss: 1.891164  [55000/100000]\n",
            "loss: 4.120112  [60000/100000]\n",
            "loss: 2.002269  [65000/100000]\n",
            "loss: 1.554129  [70000/100000]\n",
            "loss: 1.467510  [75000/100000]\n",
            "loss: 1.316177  [80000/100000]\n",
            "loss: 0.951641  [85000/100000]\n",
            "loss: 1.171327  [90000/100000]\n",
            "loss: 1.340269  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 48.4%, Avg loss: 2.169494 \n",
            "\n",
            "Epoch 6\n",
            "loss: 1.803582  [    0/100000]\n",
            "loss: 1.174330  [ 5000/100000]\n",
            "loss: 3.031339  [10000/100000]\n",
            "loss: 1.477279  [15000/100000]\n",
            "loss: 1.002304  [20000/100000]\n",
            "loss: 3.193388  [25000/100000]\n",
            "loss: 0.796993  [30000/100000]\n",
            "loss: 1.888103  [35000/100000]\n",
            "loss: 3.292131  [40000/100000]\n",
            "loss: 0.844011  [45000/100000]\n",
            "loss: 2.299024  [50000/100000]\n",
            "loss: 3.847042  [55000/100000]\n",
            "loss: 1.410877  [60000/100000]\n",
            "loss: 3.634108  [65000/100000]\n",
            "loss: 1.275283  [70000/100000]\n",
            "loss: 1.362150  [75000/100000]\n",
            "loss: 2.566764  [80000/100000]\n",
            "loss: 1.605363  [85000/100000]\n",
            "loss: 1.219314  [90000/100000]\n",
            "loss: 1.964983  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 49.5%, Avg loss: 2.147060 \n",
            "\n",
            "Epoch 7\n",
            "loss: 1.139904  [    0/100000]\n",
            "loss: 2.092155  [ 5000/100000]\n",
            "loss: 1.449289  [10000/100000]\n",
            "loss: 0.448538  [15000/100000]\n",
            "loss: 0.804774  [20000/100000]\n",
            "loss: 2.781689  [25000/100000]\n",
            "loss: 3.106471  [30000/100000]\n",
            "loss: 1.996032  [35000/100000]\n",
            "loss: 0.992252  [40000/100000]\n",
            "loss: 1.073131  [45000/100000]\n",
            "loss: 0.296455  [50000/100000]\n",
            "loss: 0.589198  [55000/100000]\n",
            "loss: 1.331756  [60000/100000]\n",
            "loss: 1.278251  [65000/100000]\n",
            "loss: 1.423040  [70000/100000]\n",
            "loss: 3.484301  [75000/100000]\n",
            "loss: 1.414500  [80000/100000]\n",
            "loss: 2.769130  [85000/100000]\n",
            "loss: 2.218956  [90000/100000]\n",
            "loss: 4.268918  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 50.8%, Avg loss: 2.102483 \n",
            "\n",
            "Epoch 8\n",
            "loss: 2.935955  [    0/100000]\n",
            "loss: 1.413387  [ 5000/100000]\n",
            "loss: 1.571962  [10000/100000]\n",
            "loss: 1.487234  [15000/100000]\n",
            "loss: 0.620026  [20000/100000]\n",
            "loss: 2.122944  [25000/100000]\n",
            "loss: 2.711750  [30000/100000]\n",
            "loss: 1.802624  [35000/100000]\n",
            "loss: 2.175187  [40000/100000]\n",
            "loss: 0.779989  [45000/100000]\n",
            "loss: 1.154595  [50000/100000]\n",
            "loss: 0.885946  [55000/100000]\n",
            "loss: 0.819612  [60000/100000]\n",
            "loss: 0.417390  [65000/100000]\n",
            "loss: 1.003862  [70000/100000]\n",
            "loss: 2.985792  [75000/100000]\n",
            "loss: 0.896574  [80000/100000]\n",
            "loss: 1.485645  [85000/100000]\n",
            "loss: 0.705431  [90000/100000]\n",
            "loss: 1.988913  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 51.5%, Avg loss: 2.115354 \n",
            "\n",
            "Epoch 9\n",
            "loss: 0.886246  [    0/100000]\n",
            "loss: 0.396091  [ 5000/100000]\n",
            "loss: 1.662880  [10000/100000]\n",
            "loss: 0.367543  [15000/100000]\n",
            "loss: 1.401939  [20000/100000]\n",
            "loss: 1.757012  [25000/100000]\n",
            "loss: 1.000170  [30000/100000]\n",
            "loss: 1.442901  [35000/100000]\n",
            "loss: 0.049577  [40000/100000]\n",
            "loss: 1.183033  [45000/100000]\n",
            "loss: 1.064708  [50000/100000]\n",
            "loss: 0.431216  [55000/100000]\n",
            "loss: 1.315047  [60000/100000]\n",
            "loss: 1.957786  [65000/100000]\n",
            "loss: 1.611449  [70000/100000]\n",
            "loss: 0.909051  [75000/100000]\n",
            "loss: 0.464363  [80000/100000]\n",
            "loss: 1.817691  [85000/100000]\n",
            "loss: 1.162234  [90000/100000]\n",
            "loss: 2.987452  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 52.0%, Avg loss: 2.093772 \n",
            "\n",
            "Epoch 10\n",
            "loss: 1.197569  [    0/100000]\n",
            "loss: 1.326279  [ 5000/100000]\n",
            "loss: 0.598402  [10000/100000]\n",
            "loss: 1.413551  [15000/100000]\n",
            "loss: 0.657819  [20000/100000]\n",
            "loss: 2.309371  [25000/100000]\n",
            "loss: 1.503145  [30000/100000]\n",
            "loss: 0.375770  [35000/100000]\n",
            "loss: 1.908453  [40000/100000]\n",
            "loss: 1.967776  [45000/100000]\n",
            "loss: 1.416154  [50000/100000]\n",
            "loss: 0.518280  [55000/100000]\n",
            "loss: 1.228411  [60000/100000]\n",
            "loss: 0.554495  [65000/100000]\n",
            "loss: 0.492008  [70000/100000]\n",
            "loss: 1.786578  [75000/100000]\n",
            "loss: 1.304393  [80000/100000]\n",
            "loss: 1.209293  [85000/100000]\n",
            "loss: 0.852505  [90000/100000]\n",
            "loss: 1.304800  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 51.8%, Avg loss: 2.147189 \n",
            "\n",
            "Epoch 11\n",
            "loss: 0.250868  [    0/100000]\n",
            "loss: 0.948460  [ 5000/100000]\n",
            "loss: 0.243400  [10000/100000]\n",
            "loss: 0.853401  [15000/100000]\n",
            "loss: 1.439776  [20000/100000]\n",
            "loss: 1.479755  [25000/100000]\n",
            "loss: 1.228492  [30000/100000]\n",
            "loss: 2.238232  [35000/100000]\n",
            "loss: 0.907217  [40000/100000]\n",
            "loss: 0.694829  [45000/100000]\n",
            "loss: 0.541629  [50000/100000]\n",
            "loss: 1.864327  [55000/100000]\n",
            "loss: 0.506066  [60000/100000]\n",
            "loss: 1.145661  [65000/100000]\n",
            "loss: 1.816981  [70000/100000]\n",
            "loss: 0.458801  [75000/100000]\n",
            "loss: 2.581661  [80000/100000]\n",
            "loss: 1.165124  [85000/100000]\n",
            "loss: 1.507482  [90000/100000]\n",
            "loss: 0.678313  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 51.8%, Avg loss: 2.191711 \n",
            "\n",
            "Epoch 12\n",
            "loss: 0.995621  [    0/100000]\n",
            "loss: 0.818428  [ 5000/100000]\n",
            "loss: 0.895486  [10000/100000]\n",
            "loss: 1.909879  [15000/100000]\n",
            "loss: 0.811031  [20000/100000]\n",
            "loss: 1.097517  [25000/100000]\n",
            "loss: 2.441639  [30000/100000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2812183fbe29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {i+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_resnet18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-8edb1dd86951>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-624d36406c8f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-624d36406c8f>\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-624d36406c8f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use cumulative moving average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiNheRgeAny1"
      },
      "source": [
        "#### Run the 2nd cell in case you want to start training from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThLwOX1Vxn6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b71a09d2-ccf2-4a6e-9173-5e99c67fb5ee"
      },
      "source": [
        "resnet18 = resnet18(pretrained=False, progress=True)\n",
        "resnet18 = resnet18.to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer_resnet18 = torch.optim.Adam(resnet18.parameters(), lr=0.0001)\n",
        "\n",
        "es =  EarlyStopping()\n",
        "lrs = LRScheduler(optimizer_resnet18)\n",
        "\n",
        "checkpoint_dir = \".\"\n",
        "test_loss = 0\n",
        "epochs = 20\n",
        "for i in range(epochs):\n",
        "    print(f\"Epoch {i+1}\")\n",
        "    train(trainloader, resnet18, loss_fn, optimizer_resnet18)\n",
        "    test_loss = test(testloader, resnet18, loss_fn)\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': i+1,\n",
        "        'model_state_dict': resnet18.state_dict(),\n",
        "        'optimizer_state_dict': optimizer_resnet18.state_dict(),\n",
        "        'loss': test_loss\n",
        "        }, checkpoint_dir+'/%04d-resnet18-model.ckpt' %i)\n",
        "    \n",
        "    lrs(test_loss)\n",
        "    es(test_loss)\n",
        "    if es.early_stop:\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "torch.save({\n",
        "        'epoch': epochs,\n",
        "        'model_state_dict': resnet18.state_dict(),\n",
        "        'optimizer_state_dict': optimizer_resnet18.state_dict(),\n",
        "        'loss': test_loss\n",
        "        }, checkpoint_dir+'/final-resnet18-model.ckpt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 5.352065  [    0/100000]\n",
            "loss: 5.026342  [ 5000/100000]\n",
            "loss: 5.068232  [10000/100000]\n",
            "loss: 4.792162  [15000/100000]\n",
            "loss: 4.535873  [20000/100000]\n",
            "loss: 4.005594  [25000/100000]\n",
            "loss: 4.534573  [30000/100000]\n",
            "loss: 3.464216  [35000/100000]\n",
            "loss: 4.451569  [40000/100000]\n",
            "loss: 4.211421  [45000/100000]\n",
            "loss: 4.269844  [50000/100000]\n",
            "loss: 3.519549  [55000/100000]\n",
            "loss: 4.488065  [60000/100000]\n",
            "loss: 4.079324  [65000/100000]\n",
            "loss: 4.992968  [70000/100000]\n",
            "loss: 3.397815  [75000/100000]\n",
            "loss: 4.923450  [80000/100000]\n",
            "loss: 4.879533  [85000/100000]\n",
            "loss: 3.459554  [90000/100000]\n",
            "loss: 3.686779  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 17.5%, Avg loss: 3.742763 \n",
            "\n",
            "Epoch 2\n",
            "loss: 2.595400  [    0/100000]\n",
            "loss: 2.785939  [ 5000/100000]\n",
            "loss: 4.787021  [10000/100000]\n",
            "loss: 4.086760  [15000/100000]\n",
            "loss: 4.019899  [20000/100000]\n",
            "loss: 3.466255  [25000/100000]\n",
            "loss: 2.713676  [30000/100000]\n",
            "loss: 3.591194  [35000/100000]\n",
            "loss: 3.448320  [40000/100000]\n",
            "loss: 4.415580  [45000/100000]\n",
            "loss: 3.737191  [50000/100000]\n",
            "loss: 5.106997  [55000/100000]\n",
            "loss: 3.211827  [60000/100000]\n",
            "loss: 4.358382  [65000/100000]\n",
            "loss: 3.022628  [70000/100000]\n",
            "loss: 4.897538  [75000/100000]\n",
            "loss: 3.585933  [80000/100000]\n",
            "loss: 2.696016  [85000/100000]\n",
            "loss: 4.163800  [90000/100000]\n",
            "loss: 3.025395  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 23.1%, Avg loss: 3.411855 \n",
            "\n",
            "Epoch 3\n",
            "loss: 3.294517  [    0/100000]\n",
            "loss: 4.466882  [ 5000/100000]\n",
            "loss: 3.999047  [10000/100000]\n",
            "loss: 3.269658  [15000/100000]\n",
            "loss: 4.260278  [20000/100000]\n",
            "loss: 3.524031  [25000/100000]\n",
            "loss: 2.382489  [30000/100000]\n",
            "loss: 2.716780  [35000/100000]\n",
            "loss: 3.926804  [40000/100000]\n",
            "loss: 4.111017  [45000/100000]\n",
            "loss: 5.749793  [50000/100000]\n",
            "loss: 3.745137  [55000/100000]\n",
            "loss: 2.532523  [60000/100000]\n",
            "loss: 2.627077  [65000/100000]\n",
            "loss: 4.155923  [70000/100000]\n",
            "loss: 2.237582  [75000/100000]\n",
            "loss: 1.810726  [80000/100000]\n",
            "loss: 4.199378  [85000/100000]\n",
            "loss: 2.731021  [90000/100000]\n",
            "loss: 2.817784  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 27.6%, Avg loss: 3.161337 \n",
            "\n",
            "Epoch 4\n",
            "loss: 3.333651  [    0/100000]\n",
            "loss: 3.053527  [ 5000/100000]\n",
            "loss: 2.679799  [10000/100000]\n",
            "loss: 2.844738  [15000/100000]\n",
            "loss: 4.856197  [20000/100000]\n",
            "loss: 3.956955  [25000/100000]\n",
            "loss: 3.670897  [30000/100000]\n",
            "loss: 3.134865  [35000/100000]\n",
            "loss: 4.117985  [40000/100000]\n",
            "loss: 2.961118  [45000/100000]\n",
            "loss: 3.708947  [50000/100000]\n",
            "loss: 1.855291  [55000/100000]\n",
            "loss: 3.242096  [60000/100000]\n",
            "loss: 2.402856  [65000/100000]\n",
            "loss: 2.228390  [70000/100000]\n",
            "loss: 2.130923  [75000/100000]\n",
            "loss: 3.133046  [80000/100000]\n",
            "loss: 3.895205  [85000/100000]\n",
            "loss: 3.694010  [90000/100000]\n",
            "loss: 3.736700  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 30.2%, Avg loss: 3.015062 \n",
            "\n",
            "Epoch 5\n",
            "loss: 2.927698  [    0/100000]\n",
            "loss: 3.246139  [ 5000/100000]\n",
            "loss: 3.921635  [10000/100000]\n",
            "loss: 1.876685  [15000/100000]\n",
            "loss: 2.436524  [20000/100000]\n",
            "loss: 2.975325  [25000/100000]\n",
            "loss: 2.702344  [30000/100000]\n",
            "loss: 2.597336  [35000/100000]\n",
            "loss: 2.670434  [40000/100000]\n",
            "loss: 0.746723  [45000/100000]\n",
            "loss: 2.462986  [50000/100000]\n",
            "loss: 3.516888  [55000/100000]\n",
            "loss: 3.462094  [60000/100000]\n",
            "loss: 2.600994  [65000/100000]\n",
            "loss: 3.796024  [70000/100000]\n",
            "loss: 3.463352  [75000/100000]\n",
            "loss: 2.288330  [80000/100000]\n",
            "loss: 1.586623  [85000/100000]\n",
            "loss: 3.623716  [90000/100000]\n",
            "loss: 2.824143  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 2.940483 \n",
            "\n",
            "Epoch 6\n",
            "loss: 3.670311  [    0/100000]\n",
            "loss: 2.075536  [ 5000/100000]\n",
            "loss: 2.613829  [10000/100000]\n",
            "loss: 1.660144  [15000/100000]\n",
            "loss: 2.264060  [20000/100000]\n",
            "loss: 4.047288  [25000/100000]\n",
            "loss: 2.287330  [30000/100000]\n",
            "loss: 3.486020  [35000/100000]\n",
            "loss: 4.413366  [40000/100000]\n",
            "loss: 2.878122  [45000/100000]\n",
            "loss: 1.802046  [50000/100000]\n",
            "loss: 2.800805  [55000/100000]\n",
            "loss: 1.466729  [60000/100000]\n",
            "loss: 1.934148  [65000/100000]\n",
            "loss: 3.833410  [70000/100000]\n",
            "loss: 2.223018  [75000/100000]\n",
            "loss: 4.020681  [80000/100000]\n",
            "loss: 3.299622  [85000/100000]\n",
            "loss: 2.498208  [90000/100000]\n",
            "loss: 2.276860  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 33.3%, Avg loss: 2.856519 \n",
            "\n",
            "Epoch 7\n",
            "loss: 1.957288  [    0/100000]\n",
            "loss: 3.058330  [ 5000/100000]\n",
            "loss: 3.479640  [10000/100000]\n",
            "loss: 2.382867  [15000/100000]\n",
            "loss: 2.540750  [20000/100000]\n",
            "loss: 2.859825  [25000/100000]\n",
            "loss: 2.293050  [30000/100000]\n",
            "loss: 1.175292  [35000/100000]\n",
            "loss: 4.023829  [40000/100000]\n",
            "loss: 2.653091  [45000/100000]\n",
            "loss: 3.550992  [50000/100000]\n",
            "loss: 3.042676  [55000/100000]\n",
            "loss: 2.230507  [60000/100000]\n",
            "loss: 1.260580  [65000/100000]\n",
            "loss: 1.517697  [70000/100000]\n",
            "loss: 3.945822  [75000/100000]\n",
            "loss: 3.597467  [80000/100000]\n",
            "loss: 4.249484  [85000/100000]\n",
            "loss: 2.409709  [90000/100000]\n",
            "loss: 1.682573  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 35.2%, Avg loss: 2.794918 \n",
            "\n",
            "Epoch 8\n",
            "loss: 2.204833  [    0/100000]\n",
            "loss: 2.711171  [ 5000/100000]\n",
            "loss: 3.894936  [10000/100000]\n",
            "loss: 3.732072  [15000/100000]\n",
            "loss: 1.229866  [20000/100000]\n",
            "loss: 2.186077  [25000/100000]\n",
            "loss: 1.783255  [30000/100000]\n",
            "loss: 3.823838  [35000/100000]\n",
            "loss: 1.204783  [40000/100000]\n",
            "loss: 1.755492  [45000/100000]\n",
            "loss: 2.619610  [50000/100000]\n",
            "loss: 2.469547  [55000/100000]\n",
            "loss: 1.340232  [60000/100000]\n",
            "loss: 3.489110  [65000/100000]\n",
            "loss: 1.938993  [70000/100000]\n",
            "loss: 2.237531  [75000/100000]\n",
            "loss: 1.484790  [80000/100000]\n",
            "loss: 2.533695  [85000/100000]\n",
            "loss: 3.494250  [90000/100000]\n",
            "loss: 2.438864  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 36.9%, Avg loss: 2.731034 \n",
            "\n",
            "Epoch 9\n",
            "loss: 1.961277  [    0/100000]\n",
            "loss: 2.882475  [ 5000/100000]\n",
            "loss: 2.060432  [10000/100000]\n",
            "loss: 1.595374  [15000/100000]\n",
            "loss: 0.912192  [20000/100000]\n",
            "loss: 1.823498  [25000/100000]\n",
            "loss: 3.086105  [30000/100000]\n",
            "loss: 1.776655  [35000/100000]\n",
            "loss: 3.569046  [40000/100000]\n",
            "loss: 1.340067  [45000/100000]\n",
            "loss: 3.106592  [50000/100000]\n",
            "loss: 1.252125  [55000/100000]\n",
            "loss: 2.101002  [60000/100000]\n",
            "loss: 2.777915  [65000/100000]\n",
            "loss: 1.622709  [70000/100000]\n",
            "loss: 2.268420  [75000/100000]\n",
            "loss: 0.814987  [80000/100000]\n",
            "loss: 2.025656  [85000/100000]\n",
            "loss: 1.937380  [90000/100000]\n",
            "loss: 2.192860  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 36.9%, Avg loss: 2.748433 \n",
            "\n",
            "Epoch 10\n",
            "loss: 1.029545  [    0/100000]\n",
            "loss: 1.870322  [ 5000/100000]\n",
            "loss: 2.078815  [10000/100000]\n",
            "loss: 2.572570  [15000/100000]\n",
            "loss: 1.347927  [20000/100000]\n",
            "loss: 2.939316  [25000/100000]\n",
            "loss: 2.997798  [30000/100000]\n",
            "loss: 1.590011  [35000/100000]\n",
            "loss: 1.085083  [40000/100000]\n",
            "loss: 3.491722  [45000/100000]\n",
            "loss: 2.357543  [50000/100000]\n",
            "loss: 2.122247  [55000/100000]\n",
            "loss: 2.386761  [60000/100000]\n",
            "loss: 1.990494  [65000/100000]\n",
            "loss: 1.206385  [70000/100000]\n",
            "loss: 3.675179  [75000/100000]\n",
            "loss: 1.974722  [80000/100000]\n",
            "loss: 3.517937  [85000/100000]\n",
            "loss: 2.612356  [90000/100000]\n",
            "loss: 2.983424  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 36.9%, Avg loss: 2.723878 \n",
            "\n",
            "Epoch 11\n",
            "loss: 2.774350  [    0/100000]\n",
            "loss: 1.965725  [ 5000/100000]\n",
            "loss: 1.850613  [10000/100000]\n",
            "loss: 2.104524  [15000/100000]\n",
            "loss: 1.923107  [20000/100000]\n",
            "loss: 2.250726  [25000/100000]\n",
            "loss: 2.233874  [30000/100000]\n",
            "loss: 0.891054  [35000/100000]\n",
            "loss: 2.885539  [40000/100000]\n",
            "loss: 2.845824  [45000/100000]\n",
            "loss: 2.506640  [50000/100000]\n",
            "loss: 0.844840  [55000/100000]\n",
            "loss: 1.672003  [60000/100000]\n",
            "loss: 2.307251  [65000/100000]\n",
            "loss: 2.039591  [70000/100000]\n",
            "loss: 0.979924  [75000/100000]\n",
            "loss: 0.514729  [80000/100000]\n",
            "loss: 2.292876  [85000/100000]\n",
            "loss: 2.022442  [90000/100000]\n",
            "loss: 1.755783  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 38.3%, Avg loss: 2.739646 \n",
            "\n",
            "Epoch 12\n",
            "loss: 1.885932  [    0/100000]\n",
            "loss: 1.883089  [ 5000/100000]\n",
            "loss: 1.161770  [10000/100000]\n",
            "loss: 2.082345  [15000/100000]\n",
            "loss: 2.023882  [20000/100000]\n",
            "loss: 1.859020  [25000/100000]\n",
            "loss: 1.196526  [30000/100000]\n",
            "loss: 2.846689  [35000/100000]\n",
            "loss: 1.356309  [40000/100000]\n",
            "loss: 1.114947  [45000/100000]\n",
            "loss: 1.943987  [50000/100000]\n",
            "loss: 2.313513  [55000/100000]\n",
            "loss: 1.143594  [60000/100000]\n",
            "loss: 3.882178  [65000/100000]\n",
            "loss: 2.311173  [70000/100000]\n",
            "loss: 2.837382  [75000/100000]\n",
            "loss: 1.467335  [80000/100000]\n",
            "loss: 1.433100  [85000/100000]\n",
            "loss: 1.599642  [90000/100000]\n",
            "loss: 2.617947  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 38.4%, Avg loss: 2.734855 \n",
            "\n",
            "Epoch 13\n",
            "loss: 0.942767  [    0/100000]\n",
            "loss: 1.016440  [ 5000/100000]\n",
            "loss: 2.712891  [10000/100000]\n",
            "loss: 1.758474  [15000/100000]\n",
            "loss: 2.777952  [20000/100000]\n",
            "loss: 1.048723  [25000/100000]\n",
            "loss: 3.627069  [30000/100000]\n",
            "loss: 1.550783  [35000/100000]\n",
            "loss: 2.719973  [40000/100000]\n",
            "loss: 1.070643  [45000/100000]\n",
            "loss: 1.719804  [50000/100000]\n",
            "loss: 1.443943  [55000/100000]\n",
            "loss: 2.417986  [60000/100000]\n",
            "loss: 2.458316  [65000/100000]\n",
            "loss: 1.680929  [70000/100000]\n",
            "loss: 2.154123  [75000/100000]\n",
            "loss: 2.509254  [80000/100000]\n",
            "loss: 3.616660  [85000/100000]\n",
            "loss: 1.629467  [90000/100000]\n",
            "loss: 1.326557  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 37.6%, Avg loss: 2.805518 \n",
            "\n",
            "Epoch 14\n",
            "loss: 1.245238  [    0/100000]\n",
            "loss: 1.222830  [ 5000/100000]\n",
            "loss: 2.796401  [10000/100000]\n",
            "loss: 2.939352  [15000/100000]\n",
            "loss: 1.095510  [20000/100000]\n",
            "loss: 0.249229  [25000/100000]\n",
            "loss: 1.332999  [30000/100000]\n",
            "loss: 2.310236  [35000/100000]\n",
            "loss: 1.147879  [40000/100000]\n",
            "loss: 0.617637  [45000/100000]\n",
            "loss: 1.153431  [50000/100000]\n",
            "loss: 2.835220  [55000/100000]\n",
            "loss: 0.806500  [60000/100000]\n",
            "loss: 1.606710  [65000/100000]\n",
            "loss: 2.831814  [70000/100000]\n",
            "loss: 1.174485  [75000/100000]\n",
            "loss: 1.394779  [80000/100000]\n",
            "loss: 1.023816  [85000/100000]\n",
            "loss: 0.926013  [90000/100000]\n",
            "loss: 2.575966  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 37.8%, Avg loss: 2.848541 \n",
            "\n",
            "Epoch 15\n",
            "loss: 1.079022  [    0/100000]\n",
            "loss: 1.919565  [ 5000/100000]\n",
            "loss: 1.498166  [10000/100000]\n",
            "loss: 1.172315  [15000/100000]\n",
            "loss: 1.913947  [20000/100000]\n",
            "loss: 1.206326  [25000/100000]\n",
            "loss: 0.661572  [30000/100000]\n",
            "loss: 1.978490  [35000/100000]\n",
            "loss: 1.187461  [40000/100000]\n",
            "loss: 1.369488  [45000/100000]\n",
            "loss: 3.122855  [50000/100000]\n",
            "loss: 1.691577  [55000/100000]\n",
            "loss: 1.696328  [60000/100000]\n",
            "loss: 1.995253  [65000/100000]\n",
            "loss: 1.212876  [70000/100000]\n",
            "loss: 3.264539  [75000/100000]\n",
            "loss: 1.486983  [80000/100000]\n",
            "loss: 2.717135  [85000/100000]\n",
            "loss: 1.232699  [90000/100000]\n",
            "loss: 1.235343  [95000/100000]\n",
            "Test Error: \n",
            " Accuracy: 37.8%, Avg loss: 2.878321 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}