{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Task_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCXZcg_Iatmx"
      },
      "source": [
        "# Task 4: Cars-196"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1bBL87WzfUd"
      },
      "source": [
        "### Mounting Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miJhvAGXzdc2",
        "outputId": "81f24ef5-57eb-4a8d-e4ea-15cb45062f82"
      },
      "source": [
        "# Mounting Google drive for loading the checkpoint.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cd gdrive/MyDrive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2b_ENW6xGZ5"
      },
      "source": [
        "### Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8InJK4txo1Ub",
        "outputId": "11b9cb11-c2d3-4207-e50f-c13d2341bb6d"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from scipy import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import torchvision.models as models\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "cuda = torch.device('cuda') \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoTShIZbxKxc"
      },
      "source": [
        "### 1. Preprocessing: Collate all image's path address & labels as a input to custom pytorch dataset\n",
        "\n",
        "### 2. Custom Pytorch datatset for training images of \"Cars-196\" with first 96 classes dataset.\n",
        "\n",
        "### 3. Custom Pytorch datatset for testing images of \"Cars-196\" with rest of 96 classes dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYc5ikJdo7Ur"
      },
      "source": [
        "file_list_train = []\n",
        "file_list_test = []\n",
        "\n",
        "labels_train = {}\n",
        "labels_test = {}\n",
        "\n",
        "mtf = io.loadmat('gdrive/MyDrive/cars/cars_train_annos.mat')\n",
        "\n",
        "for idx, img_ in enumerate(mtf['annotations'][0]):\n",
        "\n",
        "  if img_[4][0][0] <= 98:\n",
        "    dir = 'gdrive/MyDrive/cars/cars_train/' + img_[5][0]\n",
        "    labels_train[dir] = img_[4][0][0] - 1\n",
        "    file_list_train.append((dir))\n",
        "  else:\n",
        "    dir = 'gdrive/MyDrive/cars/cars_train/' + img_[5][0]\n",
        "    labels_test[dir] = img_[4][0][0] - 1 -98\n",
        "    file_list_test.append((dir))\n",
        "\n",
        "\n",
        "class TrainCarsDataset(Dataset):\n",
        "    def __init__(self, f_list, id, transform=None):\n",
        "\n",
        "        self.filenames = f_list\n",
        "        self.transform = transform\n",
        "        self.id_dict = id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = self.filenames[idx]\n",
        "        image = None\n",
        "      \n",
        "        with open(img_path, 'rb') as f:\n",
        "          image = Image.open(f)\n",
        "          image =  image.convert('RGB')\n",
        "          \n",
        "        \n",
        "        \n",
        "        label = self.id_dict[img_path]\n",
        "       \n",
        "\n",
        "        if self.transform is not None:\n",
        "\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, label\n",
        "\n",
        "\n",
        "class TrainSet(TrainCarsDataset):\n",
        "  \n",
        "    def __init__(self, f_list, id, transform=None):\n",
        "\n",
        "        super(TrainSet, self).__init__(f_list, id, transform=transform)\n",
        "\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "trans = transforms.Compose([\n",
        "            transforms.Resize(size=(64, 64)),\n",
        "            #transforms.Resize(size=(224, 224)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "trainset = TrainSet(f_list=file_list_train,id=labels_train, transform=trans)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "class TestCarsDataset(Dataset):\n",
        "    def __init__(self, f_list, id,transform=None):\n",
        "        self.filenames = f_list\n",
        "        self.transform = transform\n",
        "        self.id_dict = id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.filenames[idx]\n",
        "        image = None\n",
        "  \n",
        "        with open(img_path, 'rb') as f:\n",
        "          image = Image.open(f)\n",
        "          image =  image.convert('RGB')\n",
        "        \n",
        "        label = self.id_dict[img_path]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "trans_test = transforms.Compose([\n",
        "            transforms.Resize(size=(64, 64)),                     \n",
        "            #transforms.Resize(size=(224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "\n",
        "testset = TestCarsDataset(f_list=file_list_test,id=labels_test, transform=trans_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=4)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W6WD6FlxbrN"
      },
      "source": [
        "### CUBS Block 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBMdTO7mwUWs"
      },
      "source": [
        "class CUBS1(nn.Module):\n",
        "  def __init__(self, channels_in, n_in):\n",
        "      super(CUBS1, self).__init__()\n",
        "      self.channels_in = channels_in\n",
        "      self.n_in = n_in\n",
        "      self.dense_1_1 = nn.Linear(channels_in,n_in)\n",
        "      self.dense_1_2 = nn.Linear(channels_in,n_in)\n",
        "      self.dense_1_3 = nn.Linear(channels_in,n_in)\n",
        "      self.dense_2 = nn.Linear(n_in,channels_in)\n",
        "      self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    \n",
        "\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "      self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def CB1_Sim1(self, a, b):\n",
        "    a_norm = torch.nn.functional.normalize(a, dim=2)\n",
        "    b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "    sim_matrix = torch.matmul(a_norm[0].T, b_norm[0])\n",
        "    sim_matrix = sim_matrix.reshape((1,self.n_in,self.n_in))\n",
        "\n",
        "\n",
        "    for i in range(1,a.shape[0]):\n",
        "  \n",
        "      mul = torch.matmul(a_norm[i].T, b_norm[i]) \n",
        "      mul = mul.reshape((1,self.n_in,self.n_in))\n",
        "      sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "      \n",
        "\n",
        "    \n",
        "\n",
        "    return sim_matrix\n",
        "\n",
        "\n",
        "  def CB1_Sim2(self, a, b):\n",
        "    b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "    sim_matrix = torch.matmul(a[0], b_norm[0].T)\n",
        "    sim_matrix = sim_matrix.reshape((1,1,self.n_in))\n",
        "\n",
        "\n",
        "    for i in range(1,a.shape[0]):\n",
        "      mul = torch.matmul(a[i], b_norm[i].T)\n",
        "      mul = mul.reshape((1,1,self.n_in))\n",
        "      sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "\n",
        "    return sim_matrix\n",
        "\n",
        "  def CB1_Softmax(self, a):\n",
        "    out_matrix = nn.Softmax(dim=1)(a[0])\n",
        "    out_matrix = out_matrix.reshape((1,self.n_in,self.n_in))\n",
        "\n",
        "    for i in range(1,a.shape[0]):\n",
        "      sim = nn.Softmax(dim=1)(a[i])\n",
        "      sim = sim.reshape((1,self.n_in,self.n_in))\n",
        "      out_matrix = torch.vstack((out_matrix,sim))\n",
        "\n",
        "    return out_matrix\n",
        "\n",
        "  def CB1_Channel(self, a, b):\n",
        "    out_matrix = b[0] * a[0].unsqueeze(dim=-1). unsqueeze(dim=-1)\n",
        "\n",
        "    for i in range(1,a.shape[0]): \n",
        "      mul = b[i] * a[i].unsqueeze(dim=-1). unsqueeze(dim=-1)\n",
        "      out_matrix = torch.vstack((out_matrix,mul))\n",
        "\n",
        "    return out_matrix\n",
        "\n",
        "      \n",
        "  \n",
        "\n",
        "  def forward(self, x):\n",
        "      x_pool = self.avgpool(x)\n",
        "      x_pool = torch.reshape(x_pool,(x.shape[0],1,x.shape[1]))\n",
        "\n",
        "     \n",
        "\n",
        "      x_1_1 = self.dense_1_1(x_pool)\n",
        "     \n",
        "      \n",
        "      x_1_1 = self.relu(x_1_1)\n",
        "\n",
        "      x_1_2 = self.dense_1_2(x_pool)\n",
        "      x_1_2 = self.relu(x_1_2)\n",
        "\n",
        "      x_1_3 = self.dense_1_3(x_pool)\n",
        "      x_1_3 = self.relu(x_1_3)\n",
        "\n",
        "     \n",
        "      x_1_2_sim = self.CB1_Sim1(x_1_1, x_1_2)\n",
        "\n",
        "\n",
        "            \n",
        "      x_1_2_softmax = self.CB1_Softmax(x_1_2_sim)\n",
        "\n",
        "  \n",
        "      x_1_2_3_sim = self.CB1_Sim2(x_1_3, x_1_2_softmax)\n",
        "      \n",
        "      x_2 = self.dense_2(x_1_2_3_sim)\n",
        "      x_2 = self.relu(x_2)\n",
        "\n",
        "      x_concat_1 = torch.add(x_2, x_pool)\n",
        "      x_sig = self.sig(x_concat_1)\n",
        "\n",
        "\n",
        "      x_out = self.CB1_Channel(x_sig, x)\n",
        "      return x_out\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e432Cp7MxfYb"
      },
      "source": [
        "### CUBS Block 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLTbwvXQwVCd"
      },
      "source": [
        "\n",
        "class CUBS2(nn.Module):\n",
        "  def __init__(self, channels_in, n_in):\n",
        "      super(CUBS2, self).__init__()\n",
        "      self.channels_in = channels_in\n",
        "      self.n_in = n_in\n",
        "\n",
        "\n",
        "      self.conv_1_1 = nn.Conv2d(channels_in, 1, kernel_size=1)\n",
        "      self.conv_1_2 = nn.Conv2d(channels_in, 1, kernel_size=1)\n",
        "      self.conv_1_3 = nn.Conv2d(channels_in, 1, kernel_size=1)\n",
        "      \n",
        "   \n",
        "      \n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "      self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def CB2_Sim1(self, a, b):\n",
        "\n",
        "      a = torch.flatten(a, start_dim=2, end_dim=3)    \n",
        "      b = torch.flatten(b, start_dim=2, end_dim=3)\n",
        "\n",
        "      a_norm = torch.nn.functional.normalize(a, dim=2)\n",
        "      b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "      sim_matrix = torch.matmul(a_norm[0].T, b_norm[0])\n",
        "      sim_matrix = sim_matrix.reshape((1,a.shape[2],a.shape[2]))\n",
        "\n",
        "\n",
        "      for i in range(1,a.shape[0]):\n",
        "    \n",
        "        mul = torch.matmul(a_norm[i].T, b_norm[i]) \n",
        "        mul = mul.reshape((1,a.shape[2],a.shape[2]))\n",
        "        sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "        \n",
        "\n",
        "      return sim_matrix\n",
        "\n",
        "\n",
        "  def CB2_Sim2(self, a, b):\n",
        "\n",
        "      a = torch.flatten(a, start_dim=2, end_dim=3)\n",
        "      b_norm = torch.nn.functional.normalize(b, dim=2)\n",
        "\n",
        "      sim_matrix = torch.matmul(a[0], b_norm[0].T)\n",
        "      sim_matrix = sim_matrix.reshape((1,1,a.shape[2]))\n",
        "\n",
        "\n",
        "      for i in range(1,a.shape[0]):\n",
        "        mul = torch.matmul(a[i], b_norm[i].T)\n",
        "        mul = mul.reshape((1,1,a.shape[2]))\n",
        "        sim_matrix = torch.vstack((sim_matrix,mul))\n",
        "\n",
        "      return sim_matrix\n",
        "\n",
        "\n",
        "  def CB2_Softmax(self, a):\n",
        "      out_matrix = nn.Softmax(dim=1)(a[0])\n",
        "      out_matrix = out_matrix.reshape((1,a.shape[2],a.shape[2]))\n",
        "\n",
        "      for i in range(1,a.shape[0]):\n",
        "        sim = nn.Softmax(dim=1)(a[i])\n",
        "        sim = sim.reshape((1,a.shape[2],a.shape[2]))\n",
        "        out_matrix = torch.vstack((out_matrix,sim))\n",
        "\n",
        "      return out_matrix\n",
        "\n",
        "  \n",
        "\n",
        "  def bmul(self, vec, mat, axis=0):\n",
        "      mat = mat.transpose(axis, -1)\n",
        "      return (mat * vec.expand_as(mat)).transpose(axis, -1)\n",
        "\n",
        "  def CB1_Pixel(self, a, b):\n",
        "      a = torch.reshape(a, (a.shape[0],b.shape[2],b.shape[3]))\n",
        "    \n",
        "      a_0 = a[0]\n",
        "      b_0 = b[0]\n",
        "      out_matrix = self.bmul(a_0,b_0, axis=2)\n",
        "      out_matrix = out_matrix.reshape((1,b.shape[1],b.shape[2],b.shape[3]))\n",
        "\n",
        "      for i in range(1, a.shape[0]):\n",
        "        ai = a[i]\n",
        "        \n",
        "        bi = b[i]\n",
        "      \n",
        "        mul = self.bmul(ai,bi, axis=2)\n",
        "        mul = mul.reshape((1,b.shape[1],b.shape[2],b.shape[3]))\n",
        "        out_matrix = torch.vstack((out_matrix,mul))\n",
        "\n",
        "      return out_matrix\n",
        "      \n",
        "  def forward(self, x):\n",
        "\n",
        "     \n",
        "      x_1_1 = self.conv_1_1(x)\n",
        "      x_1_1 = self.relu(x_1_1)\n",
        "\n",
        "      x_1_2 = self.conv_1_2(x)\n",
        "      x_1_2 = self.relu(x_1_2)\n",
        "\n",
        "      x_1_3 = self.conv_1_3(x)\n",
        "      x_1_3 = self.relu(x_1_3)\n",
        "\n",
        "     \n",
        "      x_1_2_sim = self.CB2_Sim1(x_1_1, x_1_2)\n",
        "\n",
        "      x_1_2_softmax = self.CB2_Softmax(x_1_2_sim)\n",
        "\n",
        "     \n",
        "      x_1_2_3_sim = self.CB2_Sim2(x_1_3, x_1_2_softmax)\n",
        "      \n",
        "      x_sig = self.sig(x_1_2_3_sim)\n",
        "\n",
        "     \n",
        "      x_out = self.CB1_Pixel(x_sig, x)\n",
        "      \n",
        "      return x_out\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIVsmMtlxl4j"
      },
      "source": [
        "### This section contains Open-Sourced \"ResNet-18\" implementation along with various modifications and CUBS Blocks(1 & 2) experiments mentioned in the assignment.\n",
        "\n",
        "***\n",
        "\n",
        "### I've used \"BasicBlock_C\" from Task-3 as it provided me with best accuracy on testing dataset.\n",
        "\n",
        "***\n",
        "\n",
        "### BasicBlock_C : CUBS 2 -> CUBS 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BpfQV1_waf8"
      },
      "source": [
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
        "           'wide_resnet50_2', 'wide_resnet101_2']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "\n",
        "class BasicBlock_B(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock_B, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.cubs1 = CUBS1(planes, 30)\n",
        "        self.cubs2 = CUBS2(planes, 30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # CUBS 1 -> CUBS 2\n",
        "        out = self.cubs1(out)\n",
        "        out = self.cubs2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class BasicBlock_C(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock_C, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.cubs1 = CUBS1(planes, 30)\n",
        "        self.cubs2 = CUBS2(planes, 30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # CUBS 2 -> CUBS 1\n",
        "        out = self.cubs2(out)\n",
        "        out = self.cubs1(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=200, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def model_B(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock_B, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "    \n",
        "\n",
        "def model_C(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock_C, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh23GxI7yOHg"
      },
      "source": [
        "### Defining Training and Testing Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ9S5jqdwrKp"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      \n",
        "        X, y = X.to(device), y.long().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        torch.set_grad_enabled(True)\n",
        "        \n",
        "        pred = model(X).float()\n",
        "       \n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "       \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    \n",
        "        if batch % 4 == 0:\n",
        "            print(\"Loss for the batch: \", loss)\n",
        "\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "          \n",
        "            X, y = X.to(device), y.long().to(device)\n",
        "            torch.set_grad_enabled(False)\n",
        "            pred = model(X).float()\n",
        "       \n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-lJhKb4yYk1"
      },
      "source": [
        "### Defining \"Learning Rate Scheduler\" & \"Early stopping mechanism\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsQI-Gk2wwGi"
      },
      "source": [
        "class LRScheduler():\n",
        "  \n",
        "    def __init__(\n",
        "        self, optimizer, patience=5, min_lr=1e-7, factor=0.75\n",
        "    ):\n",
        "        \n",
        "        self.optimizer = optimizer\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
        "                self.optimizer,\n",
        "                mode='min',\n",
        "                patience=self.patience,\n",
        "                factor=self.factor,\n",
        "                min_lr=self.min_lr,\n",
        "                verbose=True\n",
        "            )\n",
        "    def __call__(self, val_loss):\n",
        "        self.scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "class EarlyStopping():\n",
        "   \n",
        "    def __init__(self, patience=5, min_delta=0):\n",
        "      \n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss == None:\n",
        "            self.best_loss = val_loss\n",
        "        elif self.best_loss - val_loss > self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        elif self.best_loss - val_loss < self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZkRciH7ydGb"
      },
      "source": [
        "### Instantiating & training & checkpoint \"Model_C\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXK0wMH7aXlq"
      },
      "source": [
        "#### There are 2 cells for \"Model_C\" that are given below.\n",
        "#### Run the 1st cell in case you want to load a checkpoint & resume training.\n",
        "#### Else Run the 2nd cell in case you want to start training from scratch.\n",
        "\n",
        "#### **NOTE: Make sure to change the path of loading the checkpoint in 1st cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVivqkPPaEjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29eb47f-f24b-40e7-c404-c11aa5d88cc9"
      },
      "source": [
        "model_C = model_C(pretrained=False, progress=True)\n",
        "model_C = model_C.to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer_model_C = torch.optim.Adam(model_C.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "# **NOTE: Make sure to change the path of loading the checkpoint in 1st cell**\n",
        "checkpoint = torch.load('gdrive/MyDrive/trained-model_C-model.ckpt')\n",
        "\n",
        "\n",
        "model_C.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer_model_C.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch'] + 1\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "#es =  EarlyStopping()\n",
        "#lrs = LRScheduler(optimizer_model_C)\n",
        "\n",
        "checkpoint_dir = \".\"\n",
        "test_loss = 0\n",
        "epochs = 10\n",
        "for i in range(epochs):\n",
        "    print(f\"Epoch {i+1}\")\n",
        "    train(trainloader, model_C, loss_fn, optimizer_model_C)\n",
        "    #test_loss = test(testloader, model_C, loss_fn)\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': i+1,\n",
        "        'model_state_dict': model_C.state_dict(),\n",
        "        'optimizer_state_dict': optimizer_model_C.state_dict(),\n",
        "        'loss': test_loss\n",
        "        }, checkpoint_dir+'/%04d-model_C-cars.ckpt' %i)\n",
        "    \n",
        "    #lrs(test_loss)\n",
        "    #es(test_loss)\n",
        "    #if es.early_stop: \n",
        "    #     break\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for the batch:  tensor(11.2441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(11.3082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(10.2530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(10.1868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch 2\n",
            "Loss for the batch:  tensor(9.1234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(8.4102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(8.5170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(8.0134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch 3\n",
            "Loss for the batch:  tensor(7.4658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(7.3754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(6.8968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(7.0656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch 4\n",
            "Loss for the batch:  tensor(6.3602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(6.4236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(6.3185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(6.1422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch 5\n",
            "Loss for the batch:  tensor(5.8428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.9708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.7773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.5438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch 6\n",
            "Loss for the batch:  tensor(5.5369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.5447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.3521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.4409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch 7\n",
            "Loss for the batch:  tensor(5.5586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.2932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.1729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.3281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch 8\n",
            "Loss for the batch:  tensor(5.2183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.0316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(4.9730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(5.0823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch 9\n",
            "Loss for the batch:  tensor(5.1165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(4.9911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(4.9358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(4.8958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch 10\n",
            "Loss for the batch:  tensor(4.9380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(4.9568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(4.8978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Loss for the batch:  tensor(4.8698, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd8enJRraRaO"
      },
      "source": [
        "#### Else Run the 2nd cell in case you want to start training from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ82N_rywzg3",
        "outputId": "6ccdba18-d606-44f9-8689-a65e5284867a"
      },
      "source": [
        "model_C = model_C(pretrained=False, progress=True)\n",
        "model_C = model_C.to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer_model_C = torch.optim.Adam(model_C.parameters(), lr=0.0001)\n",
        "\n",
        "#es =  EarlyStopping()\n",
        "#lrs = LRScheduler(optimizer_model_C)\n",
        "\n",
        "checkpoint_dir = \".\"\n",
        "test_loss = 0\n",
        "epochs = 20\n",
        "for i in range(epochs):\n",
        "    print(f\"Epoch {i+1}\")\n",
        "    train(trainloader, model_C, loss_fn, optimizer_model_C)\n",
        "    #test_loss = test(testloader, model_C, loss_fn)\n",
        "    \n",
        "    torch.save({\n",
        "        'epoch': i+1,\n",
        "        'model_state_dict': model_C.state_dict(),\n",
        "        'optimizer_state_dict': optimizer_model_C.state_dict(),\n",
        "        'loss': test_loss\n",
        "        }, checkpoint_dir+'/%04d-model_C-cars.ckpt' %i)\n",
        "    \n",
        "    #lrs(test_loss)\n",
        "    #es(test_loss)\n",
        "    #if es.early_stop:\n",
        "    #  break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 5.467802  [    0/ 4052]\n",
            "Epoch 2\n",
            "loss: 4.352901  [    0/ 4052]\n",
            "Epoch 3\n",
            "loss: 3.913038  [    0/ 4052]\n",
            "Epoch 4\n",
            "loss: 4.234994  [    0/ 4052]\n",
            "Epoch 5\n",
            "loss: 3.279977  [    0/ 4052]\n",
            "Epoch 6\n",
            "loss: 2.858897  [    0/ 4052]\n",
            "Epoch 7\n",
            "loss: 3.137208  [    0/ 4052]\n",
            "Epoch 8\n",
            "loss: 2.361117  [    0/ 4052]\n",
            "Epoch 9\n",
            "loss: 1.805948  [    0/ 4052]\n",
            "Epoch 10\n",
            "loss: 1.088871  [    0/ 4052]\n",
            "Epoch 11\n",
            "loss: 0.942495  [    0/ 4052]\n",
            "Epoch 12\n",
            "loss: 0.434313  [    0/ 4052]\n",
            "Epoch 13\n",
            "loss: 0.284304  [    0/ 4052]\n",
            "Epoch 14\n",
            "loss: 0.723998  [    0/ 4052]\n",
            "Epoch 15\n",
            "loss: 0.388277  [    0/ 4052]\n",
            "Epoch 16\n",
            "loss: 0.229776  [    0/ 4052]\n",
            "Epoch 17\n",
            "loss: 0.204802  [    0/ 4052]\n",
            "Epoch 18\n",
            "loss: 0.344304  [    0/ 4052]\n",
            "Epoch 19\n",
            "loss: 0.327055  [    0/ 4052]\n",
            "Epoch 20\n",
            "loss: 0.389437  [    0/ 4052]\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 0.043564 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvUG1JwW0vPg"
      },
      "source": [
        "### Defining a new model that is a copy of previously trained model, but with last classification layer chopped off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZJcq94W0rCS"
      },
      "source": [
        "new_model = torch.nn.Sequential(*(list(model_C.children())[:-1]))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4nVK5eYb_YF"
      },
      "source": [
        "### Defining \"eval\" function to get \"512 feature embeddings (predictions)\" for whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7i1_7_lo5e_"
      },
      "source": [
        "def eval(dataloader, model, loss_fn):\n",
        "   \n",
        "    model.eval()\n",
        "    predictions = None\n",
        "    labels = None\n",
        "  \n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            \n",
        "            X, y = X.to(device), y.long().to(device)\n",
        "            torch.set_grad_enabled(False)\n",
        "            pred = model(X).float()\n",
        "            pred = pred.reshape((pred.shape[0],pred.shape[1]))\n",
        "\n",
        "            if predictions == None:\n",
        "              predictions = pred\n",
        "              labels = y\n",
        "            else:\n",
        "              predictions = torch.vstack((predictions,pred))\n",
        "              labels = torch.hstack((labels,y))\n",
        "        \n",
        "            \n",
        "\n",
        "    return predictions, labels\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6gdkNnkcIDp"
      },
      "source": [
        "### Defining \"similarity\" fucntion to calculate Similarity-matrix between the \"512 feature embeddings (predictions)\" for whole dataset/batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqak-2Kn7xdS"
      },
      "source": [
        "def similarity(preds):\n",
        "      preds_T = preds.T\n",
        "\n",
        "      preds_norm = torch.linalg.norm(preds, dim=1, keepdim=True)  \n",
        "      preds_T_norm = torch.linalg.norm(preds_T, dim=0, keepdim=True) \n",
        "\n",
        "      sim = ((preds @ preds_T) / (preds_norm @ preds_T_norm)).T\n",
        "      return sim"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amM7v2JucrSz"
      },
      "source": [
        "### Defining a function to calculate \"Recall @ k\" for the given dataset/batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEwtw5GrpN3g"
      },
      "source": [
        "# Recall@k\n",
        "\n",
        "def recall_k(sim,y,k):\n",
        "  \n",
        "  recall = 0\n",
        "  for i in range(sim.shape[0]):\n",
        "\n",
        "    sim_i_list = sim[i]\n",
        "\n",
        "    sorted_ind = torch.argsort(sim_i_list, descending=True)\n",
        "    sorted_ind = sorted_ind[:k+1]\n",
        "\n",
        "\n",
        "    recall_cnt = 0\n",
        "    for j in sorted_ind:\n",
        "     \n",
        "      if y[j] == y[i] and j != i:\n",
        "        \n",
        "        recall_cnt +=1\n",
        "\n",
        "\n",
        "    recall_cnt = recall_cnt/k\n",
        "\n",
        "    recall += recall_cnt\n",
        "\n",
        "\n",
        "\n",
        "  recall = recall / sim.shape[0]\n",
        "\n",
        "  return recall"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-i4K3KHg1Lx"
      },
      "source": [
        "### Calculate \"Recall @K\" values for the finetuned model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFRvW7bzpMFw",
        "outputId": "5c4eb1a0-a96f-4a93-d04f-e9bdc49103ce"
      },
      "source": [
        "out, y = eval(testloader, new_model, loss_fn) \n",
        "sim1 = similarity(out)\n",
        "rc1 = recall_k(sim1,y,1)\n",
        "rc2 = recall_k(sim1,y,2)\n",
        "rc4 = recall_k(sim1,y,4)\n",
        "rc8 = recall_k(sim1,y,8)\n",
        "\n",
        "print(\"Recall at 1: \",rc1)\n",
        "print(\"Recall at 2: \",rc2)\n",
        "print(\"Recall at 4: \",rc4)\n",
        "print(\"Recall at 8: \",rc8)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall at 1:  0.0747800586510264\n",
            "Recall at 2:  0.060117302052785926\n",
            "Recall at 4:  0.047653958944281524\n",
            "Recall at 8:  0.038581378299120235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w4KuoXifgck"
      },
      "source": [
        "### Defining Custom Loss to Re-train the \"new_model\"\n",
        "### **Note: \"util\" function is used to mine \"Hard Negative/Positive Samples\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_ZfztSWVgwc"
      },
      "source": [
        "class CustomLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(CustomLoss, self).__init__()      \n",
        "        self.loss = 0\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        self.loss = self.custom_loss(output, target)\n",
        "        return self.loss\n",
        "\n",
        "\n",
        "    def similarity(self, preds):\n",
        "      preds_T = preds.T\n",
        "\n",
        "      preds_norm = torch.linalg.norm(preds, dim=1, keepdim=True)  \n",
        "      preds_T_norm = torch.linalg.norm(preds_T, dim=0, keepdim=True) \n",
        "\n",
        "      sim = ((preds @ preds_T) / (preds_norm @ preds_T_norm)).T\n",
        "      return sim\n",
        "\n",
        "\n",
        "    # Function to select Hard Negative/Positive Mining sets\n",
        "    def util(self, sim, out,y):\n",
        "      hard_p = {}\n",
        "      hard_n = {}\n",
        "\n",
        "      for lab_i, lab in enumerate(y):\n",
        "        hard_p[lab_i] = []\n",
        "        hard_n[lab_i] = []\n",
        "\n",
        "\n",
        "\n",
        "      for ind_i,i in enumerate(sim):\n",
        "\n",
        "        sim_i_list = i\n",
        "        \n",
        "\n",
        "        sorted_ind = torch.argsort(sim_i_list, descending=True)\n",
        "\n",
        "        # Hard Negative/Positive Mining threshold\n",
        "        k = int(sorted_ind.shape[0]/2)\n",
        "\n",
        "        hard_p_prospective = sorted_ind[-k:]\n",
        "        hard_n_prospective = sorted_ind[:k]\n",
        "\n",
        "  \n",
        "        for k in hard_p_prospective:\n",
        "          if ind_i == k:\n",
        "            continue\n",
        "          elif y[ind_i] == y[k]:\n",
        "            hard_p[ind_i].append(k)\n",
        "\n",
        "        for k in hard_n_prospective:\n",
        "          if ind_i == k:\n",
        "            continue\n",
        "          elif y[ind_i] != y[k]:\n",
        "            hard_n[ind_i].append(k)\n",
        "            \n",
        "\n",
        "            \n",
        "\n",
        "      return hard_p, hard_n\n",
        "\n",
        "\n",
        "\n",
        "    # Custom Loss Formula\n",
        "    def loss_formula(self, batch, sim, p, n, alpha=5, beta=50, lamb=0.5):\n",
        "\n",
        "\n",
        "      psum_batch = 0\n",
        "      nsum_batch = 0\n",
        "\n",
        "      for index in range(batch):\n",
        "\n",
        "        nsum = 0\n",
        "        for i in n[index]:\n",
        "          exp_pow = beta*(sim[index][i] - lamb)\n",
        "          nsum += torch.exp(exp_pow)\n",
        "\n",
        "        nsum_batch += (1/beta)*(1 + nsum)\n",
        "      \n",
        "\n",
        "        psum = 0\n",
        "        for i in p[index]:\n",
        "          exp_pow = -alpha*(sim[index][i] - lamb)\n",
        "          psum += torch.exp(exp_pow)\n",
        "\n",
        "        psum_batch += (1/alpha)*(1 + psum)\n",
        "\n",
        "\n",
        "\n",
        "      loss = (psum_batch + nsum_batch)/batch\n",
        "\n",
        "      return loss\n",
        "\n",
        "\n",
        "    def custom_loss(self, output, target):\n",
        "        \n",
        "        sim = self.similarity(output)\n",
        "        p, n = self.util(sim,output,target)\n",
        "\n",
        "        batch =output.shape[0]\n",
        "\n",
        "        loss = self.loss_formula(batch, sim, p, n)\n",
        "        \n",
        "        return loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaRYfdaug9RA"
      },
      "source": [
        "### Defining a new training function for the new \"CustomLoss\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuSkiPKef4vi"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      \n",
        "        X, y = X.to(device), y.long().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        torch.set_grad_enabled(True)\n",
        "        \n",
        "        pred = model(X).float()\n",
        "        pred = pred.reshape((pred.shape[0],pred.shape[1]))\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "       \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    \n",
        "        print(\"Loss for the Batch\",loss)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgD-YVeXhKPv"
      },
      "source": [
        "### Re-train the \"new_model\" with the \"CustomLoss\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWHNbYuGfxIV",
        "outputId": "ff8c182c-c70a-4e21-8d15-ae33fef6bd2c"
      },
      "source": [
        "checkpoint_dir = \".\"\n",
        "\n",
        "cust_loss = CustomLoss()\n",
        "test_loss = 0\n",
        "epochs = 10\n",
        "optimizer_new_model = torch.optim.Adam(new_model.parameters(), lr=0.0001)\n",
        "for i in range(epochs):\n",
        "    print(\"Epoch: \", i)\n",
        "    train(trainloader, new_model, cust_loss, optimizer_new_model)\n",
        "    torch.save({\n",
        "        'epoch': i+1,\n",
        "        'model_state_dict': new_model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer_new_model.state_dict(),\n",
        "        'loss': test_loss\n",
        "        }, checkpoint_dir+'/%04d-new_model-cars-custom-loss.ckpt' %i)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n",
            "Loss for the Batch tensor(59889952., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(38932596., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(17139378., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(9905732., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(8641176., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(3913825., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(4709531., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(4082372.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(2158048.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(4107710., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(3302969.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(1870881.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(1136326.3750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(749738.6250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(745795.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(632242.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch:  1\n",
            "Loss for the Batch tensor(575565.8750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(754759.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(1038998., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(519859., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(417776.4375, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(1440654.6250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(402049.9688, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(609181.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(343763.8125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(1688189.7500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(286818.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(431083.5312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(236220.6719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(1220137.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(276348.6875, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(372417., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch:  2\n",
            "Loss for the Batch tensor(1120393.6250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(206516.6406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(240372.7500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(199316.6250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(282831.1875, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(142906.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(195035.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(271480.7812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(334658.9375, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(211004.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(195276.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(135715., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(222344.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(141429.8906, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(160005.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(118806.7734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch:  3\n",
            "Loss for the Batch tensor(174303.5469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(147280.9844, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(146097.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(185319.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(241275.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(211634.4531, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(161562.8125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(140852.3750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(114995.9766, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(124855.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(144918.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(111426.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(123571.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(242846.6719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(167237.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(168930.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch:  4\n",
            "Loss for the Batch tensor(142032.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(138606.9688, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(181427.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(116596.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(147625.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(116058.6719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(258215.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(111747.9141, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(11454152., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(103384.5703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(92844.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(144223., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(164368.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(130633.5547, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(82031.8203, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(89588.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch:  5\n",
            "Loss for the Batch tensor(153044.5625, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(162267.8438, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(176156.9688, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(88499.8359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(94414.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(136057.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(202596.2969, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(137255.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(94512.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(1629458.3750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(181751.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(91578.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(64144.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(127647.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(119188.8828, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(62876.6328, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch:  6\n",
            "Loss for the Batch tensor(74498.9297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(86384.8594, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(82210.7344, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(120158.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(95004.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(101814.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(150037.7031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(154597.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(94607.3984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(66634.9375, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(66065.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(171852., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(80256.7578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(11327274., device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(133466.8125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(88991.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch:  7\n",
            "Loss for the Batch tensor(58988.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(142961.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(150232.9375, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(57421.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(109036.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(84422.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(72305.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(70821.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(79897.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(146167.7812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(53687.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(59378.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(122079.7969, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(93485.6484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(61522.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(56288.9102, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch:  8\n",
            "Loss for the Batch tensor(54701.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(69130.5547, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(67934.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(155551.6250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(55434.8242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(71304.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(55811.9453, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(46047.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(77473.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(88692.9062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(68568.8906, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(65531.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(42926.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(202618.5312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(46548.0469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(74557.6953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch:  9\n",
            "Loss for the Batch tensor(77735.8203, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(49776.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(48432.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(73015.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(80047.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(68682.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(77083.0391, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(79557.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(52428.9570, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(52324.3516, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(39925.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(59262.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(99949.0547, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(70926.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(91196.9062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss for the Batch tensor(62918.6836, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zq2oWOygU06"
      },
      "source": [
        "### Calculate Final \"Recall @K\" values for the re-trained model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3ityBP9V4MF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2f01d4-7a54-444a-e08a-e655c66caf46"
      },
      "source": [
        "out, y = eval(testloader, new_model, loss_fn) \n",
        "sim1 = similarity(out)\n",
        "rc1 = recall_k(sim1,y,1)\n",
        "rc2 = recall_k(sim1,y,2)\n",
        "rc4 = recall_k(sim1,y,4)\n",
        "rc8 = recall_k(sim1,y,8)\n",
        "\n",
        "print(\"Recall at 1: \",rc1)\n",
        "print(\"Recall at 2: \",rc2)\n",
        "print(\"Recall at 4: \",rc4)\n",
        "print(\"Recall at 8: \",rc8)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall at 1:  0.08504398826979472\n",
            "Recall at 2:  0.06867057673509286\n",
            "Recall at 4:  0.05510752688172043\n",
            "Recall at 8:  0.04536290322580645\n"
          ]
        }
      ]
    }
  ]
}